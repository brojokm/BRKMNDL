<html>
<body>
All right, let is get started. We return today to graph search. Last time we saw breadth first search, today we are going to do depth first search. It is a simple algorithm, but you can do lots of cool things with it. And that is what I will spend most of today on, in particular, telling whether your graph has a cycle, and something called topological sort. As usual, basically in all graph algorithms in this class, the input, the way the graph is specified is as an adjacency list, or I guess adjacency list plural. So you have a bunch of lists, each one says for each vertex, what are the vertices I am connected to? What are the vertices I can get to in one step via an edge? So that is our input and our goal, in general, with graph search is to explore the graph. In particular, the kind of exploration we are going to be doing today is to visit all the vertices, in some order, and visit each vertex only once. So the way we did breadth first search, breadth first search was really good. It explored things layer by layer, and that was nice because it gave us shortest paths, it gave us the fastest way to get to everywhere, from a particular source, vertex s. But if you ca not get from s to your vertex, than the shortest way to get there is infinity, there is no way to get there. And BFS is good for detecting that, it can tell you which vertices are unreachable from s. DFS can do that as well, but it is often used to explore the whole graph, not just the part reachable from s, and so we are going to see how to do that today. This trick could be used for be BFS or for DFS, but we are going to do it here for DFS, because that is more common, let is say. So DFS. So depth first search is kind of like how you solve a maze. Like, the other weekend I was at the big corn maze in central Massachusetts, and it is easy to get lost in there, in particular, because I did not bring any bread crumbs. The proper way to solve a maze, if you are in there and all you can do is see which way to go next and then walk a little bit to the next junction, and then you have to keep making decisions. Unless you have a really good memory, which I do not, teaching staff can attest to that, then an easy way to do it is to leave bread crumbs behind, say, this is the last way I went from this node, so that when I reach a deadend, I have to turn around and backtrack. I reach a breadcrumb that say, oh, last time you went this way, next time you should go this way, and in particular, keep track at each node, which of the edges have I visited, which ones are still left to visit. And this can be done very easily on a computer using recursion. So high level description is we are going to just recursively explore the graph, backtracking as necessary, kind of like how you solve a maze. In fact, when I was seven years old, one of the first computer programs I wrote was for solving a maze. I did not know it was depth first search at the time, but now I know. It was so much harder doing algorithms when I did not know what they were. Anyway, I am going to write some code for depth first search, it is super simple code, the simplest graph algorithm. It is four lines. That is it. I am going to write a little bit of code after this, but this is basic depth first search. This will visit all the vertices reachable from a given source, vertex s. So we are given the adjacency list. I do not know why I put v here, you could erase it, it is not necessary. And all we do is, we have our vertex b, sorry, we have our vertex s. We look at all of the outgoing edges from s. For each one, we will call it v, we check, have I visited this vertex already? A place where we need to be careful is to not repeat vertices. We need to do this in BFS as well. So, the way we are going to do that is by setting the parent of a node, we will see what that actually means later. But for now, it is just, are you in the parent structure or not? This is initially, we have seen s, so we give it a parent of nothing, but it exists in this dictionary. If the vertex b that we are looking at is not in our dictionary, we have not seen it yet, we mark it as seen by setting its parent to s, and then we recursively visit it. That is it. Super simple, just recurse. Sort of the magical part is the preventing yourself from repeating. As you explore the graph, if you reach something you have already seen before you just skip it again. So you only visit every vertex once, at most once. This will not visit the entire graph, it will only visit the vertices reachable from s. The next part of the code I had like to give you is for visiting all the vertices, and in the textbook this is called the DFS, whereas this is just called DFS visit, that is sort of the recursive part, and this is sort of a top level algorithm. Here we are going to use the set of vertices, b, and here we are just going to iterate over the s is. So it looks almost the same, but what we are iterating over is different. Here we are iterating over the outgoing edges from s, here were iterating over the choices of s. So the idea here is we do not really know where to start our search. If it is a disconnected graph or not a strongly connected graph, we might have to start our search multiple times. This DFS algorithm is finding all the possible places you might start the search and trying them all. So it is like, OK, let is try the first vertex. If that has not been visited, which initially nothing is been visited, then visit it, recursively, everything reachable from s. Then you go on to the second vertex. Now, you may have already visited it, then you skip it. Third vertex, maybe you visited it already. Third, fourth vertex, keep going, until you find some vertex you have not visited at all. And then you recursively visit everything reachable from it, and you repeat. This will find all the different clusters, all the different strongly connected components of your graph. Most of the work is being done by this recursion, but then there is this top level, just to make sure that all the vertices get visited. Let is do a little example, so this is super clear, and then it will also let me do something called edge classification. Once we see every edge in the graph gets visited by DFS in one way or another, and it is really helpful to think about the different ways they can be visited. So here is a graph. I think its a similar to one from last class. It is not strongly connected, I do not think, so you ca not get from these vertices to c. You can get from c to everywhere, it looks like, but not strongly connected. And we are going to run DFS, and I think, basically in alphabetical order is how we are imagining these vertices have to be ordered somehow, we do not really care how, but for sake of example I care. So we are going to start with a, that is the first vertex in here. We are going to recursively visit everything reachable from a, so we enter here with s equals a. So I will mark this s1, to be the first value of s at this level. So we consider I am going to check the order here first edge we look at, there is two outgoing edges, let is say we look at this one first. We look at b, b has not been visited yet, has no parent pointer. This one has a parent pointer of zero point B we are going to give a parent pointer of a, that is here. Then we recursively visit everything for b. So we look at all the outgoing edges from b, there is only one. So we visit this edge. for b to e. e has not been visited, so we set as parent pointer to b, an now we recursively visit e. e has only one outgoing edge, so we look at it, over here to d. d has not been visited, so we set a parent pointer to e, and we look at all the outgoing edges from d. d has one outgoing edge, which is to b. b has already been visited, so we skip that one, nothing to do. That is the else case of this if, so we do nothing in the else case, we just go to the next edge. But there is no next edge for d, so we are done. So this algorithm returns to the next level up. Next level up was e, we were iterating over the outgoing edges from e. But there was only one, so we are done, so e finishes. Then we backtrack to b, which is always going back along the parent pointer, but it is also just in the recursion. We know where to go back to. We were going over the outgoing edges from b, there is only one, we are done. So we go back to a. We only looked at one outgoing edge from a. There is another outgoing edge, which is this one, but we have already visited d, so we skip over that one, too, so we are done recursively visiting everything reachable from a. Now we go back to this loop, the outer loop. So we did a, next we look at b, we say, oh b has been visited, we do not need to do anything from there. Then we go to c, c has not been visited so we are going to loop from c, and so this is our second choice of s in this recursion, or in this outer loop. And so we look at the outgoing edges from s2, let me match the order in the notes. Let is say first we go to f. f has not been visited, so we set its parent pointer to c. Then we look at all the outgoing edges from f. There is one outgoing edge from f, it goes to f. I guess I should not really bold this, sorry. I will say what the bold edges mean in a moment. This is just a regular edge. We follow the edge from f to f. We see, oh, f has already been visited, it already has a parent pointer, so there is no point going down there. We are done with f, that is the only outgoing edge. We go back to c, there is one other outgoing edge, but it leads to a vertex we have already visited, namely e, and so we are done with visiting everything reachable from c. We did not visit everything reachable from c, because some of it was already visited from a. Then we go back to the outer loop, say, OK, what about d? D has been visited, what about e? E is been visited, what about f? F is been visited. So we are visiting these vertices again, but should only be twice in total, and in the end we visit all the vertices, and, in a certain sense, all the edges as well. Let is talk about running time. What do you think the running time of this algorithm is? Anyone? Time to wake up. Upper bound? Upper bound, sure. V? V? . V is a little bit optimistic, plus e, good, collaborative effort. It is linear time, just like BFS. This is what we call linear time, because this is the size of the input. It is theta V plus E for the whole thing. The size of the input was v plus e. We needed v slots in an array, plus we needed e items in these linked lists, one for each edge. We have to traverse that whole structure. The reason it is order v plus e is first, as you were saying, you are visiting every vertex once in this outer loop, so not worrying about the recursion in DFS alone, so that is order b. Then have to worry about this recursion, but we know that whenever we call DFS visit on a vertex, that it did not have a parent before. Right before we called DFS visit, we set its parent for the first time. Right before we called DFS visit on v here, we set as parent for the first time, because it was not set before. So DFS visit, and I am going to just write of v, meaning the last argument here. It is called once, at most once, per vertex b. But it does not take constant time. This takes constant time per vertex, plus a recursive call. This thing, this takes constant time, but there is a for loop here. We have to pay for however many outgoing edges there are from b, that is the part you are missing. And we pay length of adjacency of v for that vertex. So the total in addition to this v is going to be the order, sum overall vertices, v in capital V, of length of the adjacency, list for v, which is E. This is the handshaking lemma from last time. It is twice e for undirected graphs, it is e for directed graphs. I have drawn directed graphs here, it is a little more interesting. OK, so it is linear time, just like the BFS, so you could say, who cares, but DFS offers a lot of different properties than BFS. They each have their niche. BFS is great for shortest paths. You want to know the fastest way to solve the Rubik is cube, BFS will find it. You want to find the fastest way to solve the Rubik is cube, DFS will not find it. It is not following shortest paths here. Going from a to d, we use the path of length 3, that is the bold edges. We could have gone directly from a to d, so it is a different kind of search, but sort of the inverse. But it is extremely useful, in particular, in the way that it classifies edges. So let me talk about edge classification. You can check every edge in this graph gets visited. In a directed graph every edge gets visited once, in an undirected graph, every edge gets visited twice, once from each side. And when you visit that edge, there is sort of different categories of what could happen to it. Maybe the edge led to something unvisited, when you went there. We call those tree edges. That is what the parent pointers are specifying and all the bold edges here are called three edges. This is when we visit a new vertex via that edge. So we look at the other side of the edge, we discover a new vertex. Those are what we call tree edges, it turns out they form a tree, a directed tree. That is a lemma you can prove. You can see it here. We just have a path, actually a forest would be more accurate. We have a path abed, and we have an edge cf, but, in general, it is a forest. So for example, if there was another thing coming from e here, let is modify my graph, we would, at some point, visit that edge and say, oh, here is a new way to go, and now that bold structure forms an actual tree. These are called tree edges, you can call them forest edges if you feel like it. There are other edges in there, the nonbold edges, and the textbook distinguishes three types, three types? Three types, so many types. They are forward edges, backward edges, and cross edges. Some of these are more useful to distinguish than others, but it does not hurt to have them all. So, for example, this edge I am going to call a forward edge, just write f, that is unambiguous, because it goes, in some sense, forward along the tree. It goes from the root of this tree to a descendant. There is a path in the tree from a to d, so we call it a forward edge. By contrast, this edge I am going to call a backward edge, because it goes from a node in the tree to an ancestor in the trees. If you think of parents, I can go from d to its parent to its parent, and that is where the edge goes, so that is a backward edge double check I got these not reversed, yeah, that is right. Forward edge because I could go from d to its parent to its parent to its parent and the edge went the other way, that is a forward edge. So forward edge goes from a node to a descendant in the tree. Backward edge goes from a node to an ancestor in the tree. And when I say, tree, I mean forest. And then all the other edges are cross edges. So I guess, here, this is a cross edge. In this case, it goes from one tree to another, does not have to go between different trees. For example, let is say I am visiting d, then I go back to e, I visit g, or there could be this edge. If this edge existed, it would be a cross edge, because g and d are not ancestor related, neither one is an ancestor of the other, they are siblings actually. So there is, in general, there is going to be some subtree over here, some subtree over here, and this is a cross edge between two different subtrees. This cross edge is between two, sort of, non ancestor related, I think is the shortest way to write this, subtrees or nodes. A little puzzle for you, well, I guess the first question is, how do you compute this structure? How do you compute which edges are which? This is not hard, although I have not written it in the code here. You can check the textbook for one way to do it. The parent structure tells you which edges are tree edges. So that part we have done. Every parent pointer corresponds to the reverse of a tree edge, so at the same time you could mark that edge a tree edge, and you had know which edges are tree edges and which edges are nontree edges. If you want to know which are forward, which are backward, which are cross edges, the key thing you need to know is, well, in particular, for backward edges, one way to compute them is to mark which nodes you are currently exploring. So when we do a DFS visit on a node, we could say at the beginning here, basically, we are starting to visit s, say, start s, and then at the end of this for loop, we write, we are finished with s. And you could mark that in the s structure. You could say s dot in process is true up here, s dot in process equals false down here. Keep track of which nodes are currently in the recursion stack, just by marking them and unmarking them at the beginning and the end. Then we will know, if we follow an edge and it is an edge to somebody who is already in the stack, then it is a backward edge, because that is everyone in the stack is an ancestor from our current node. Detecting forward edges, it is a little trickier. Forward edges versus cross edges, any suggestions on an easy way to do that? I do not think I know an easy way to do that. It can be done. The way the textbook does it is a little bit more sophisticated, in that when they start visiting a vertex, they record the time that it got visited. What is time? You could think of it as the clock on your computer, another way to do it is, every time you do a step in this algorithm, you increment a counter. So every time anything happens, you increment a counter, and then you store the value of that counter here for s, that would be the start time for s, you store the finish time for s down here, and then this gives you, this tells you when a node was visited, and you can use that to compute when an edge is a forward edge and otherwise it is a cross edge. It is not terribly exciting, though, so I am not going to detail that. You can look at the textbook if you are interested. But here is a fun puzzle. In an undirected graph, which of these edges can exist? We can have a vote, do some democratic mathematics. How many people think tree edges exist in undirected graphs? You, OK. Sarini does. That is a good sign. How many people think forward edges exist in an undirected graph? A couple. How many people think backward edges exist in an undirected graph? Couple. How many people think cross edges exist in undirected graph? More people, OK. I think voting worked. They all exist, no, that is not true. This one can exist and this one can exist. I actually wrote the wrong ones in my notes, so it is good to trick you, no, it is I made a mistake. It is very easy to get these mixed up and you can think about why this is true, maybe I will draw some pictures to clarify. This is something, you remember the there was BFS diagram, I talked a little bit about this last class. Tree edges better exist, those are the things you use to visit new vertices. So that always happens, undirected or otherwise. Forward edges, though, forward edge of would be, OK, I visited this, then I visited this. Those were tree edges. Then I backtrack and I follow an edge like this. This would be a forward edge. And in a directed graph that can happen. In an undirected graph, it can also happen, right? Oh, no, it ca not, it ca not. OK. So confusing. undirected graph, if you look like this, you start let is say this is s. You start here, and suppose we follow this edge. We get to here, then we follow this edge, we get to here. Then we will follow this edge in the other direction, and that is guaranteed to finish before we get back to s. So, in order to be a forward edge, this one has to be visited after this one, from s, but in this scenario, if you follow this one first, you will eventually get to this vertex and then you will come back, and then that will be classified as a backward edge in an undirected graph. So you can never have forward edges in an undirected graph. But I have a backward edge here, that would suggest I can have backward edges here, and no cross edges. Well, democracy did not work, I was swayed by the popular vote. So I claim, apparently, cross edges do not exist. Let is try to draw this. So a cross edge typical scenario would be either here, you follow this edge, you backtrack, you follow another edge, and then you discover there is was an edge back to some other subtree that you have already visited. That can happen in an undirected graph. For the same reason, if I follow this one first, and this edge exists undirected, then I will go down that way. So it will be actually tree edge, not a cross edge. OK, phew. That means my notes were correct. I was surprised, because they were copied from the textbook, uncorrect my correction. Good. So what? Why do I care about these edge classifications? I claim they are super handy for two problems, cycle detection, which is pretty intuitive problem. Does my graph have any cycles? In the directed case, this is particularly interesting. I want to know, does a graph have any directed cycles? And another problem called topological sort, which we will get to. So let is start with cycle detection. This is actually a warmup for topological sort. So does my graph have any cycles? G has a cycle, I claim. This happens, if and only if, G has a back edge, or let is say, a depth first search of that graph has a back edge. So it does not matter where I start from or how this algorithm I run this top level DFS algorithm, explore the whole graph, because I want to know in the whole graph is there a cycle? I claim, if there is a back edge, then there is a cycle. So it all comes down to back edges. This will work for both directed and undirected graphs. Detecting cycles is pretty easy in undirected graphs. It is a little more subtle with directed graphs, because you have to worry about the edge directions. So let is prove this. We have not done a serious proof in a while, so this is still a pretty easy one, let is think about it. What do you think is the easier direction to prove here, left or right? To more democracy. How many people think left is easy? A couple. How many people think right is easy? A whole bunch more. I disagree with you. I guess it depends what you consider easy. Let me show you how easy left is. Left is, I have a back edge, I want to claim there is a cycle. What is the back edge look like? Well, it is an edge to an ancestor in the tree. If this node is a descendant of this node and this node is an ancestor of this node, that is saying there are tree edges, there is a path, a tree path, that connects one to the other. So these are tree edges, because this is supposed to be an ancestor, and this is supposed to be a descendant. And that is the definition of a back edge. Do you see a cycle? I see a cycle. This is a cycle, directed cycle. So if there is a back edge, by definition, it makes a cycle. Now, it is harder to say if I have ten back edges, how many cycles are there? Could be many. But if there is a back edge, there is definitely at least one cycle. The other direction is also not too hard, but I would hesitate to call it easy. Any suggestions if, I know there is a cycle, how do I prove that there is a back edge somewhere? Think about that, let me draw a cycle. There is a length k cycle. Where do you think, which of these edges do you think is going to be a back edge? Let is hope it is one of these edges. Sorry? Vk to v zero. Vk to v zero. That is a good idea, maybe this is a back edge. Of course, this is symmetric, why that edge? I labeled it in a suggestive way, but I need to say something before I know actually which edge is going to be the back edge. You have to say you start to v zero? Start at v zero. If I started a search of v zero, that looks good, because the search is kind of going to go in this direction. vk will maybe be the last thing to be visited, that is not actually true. Could be there is an edge directly from v zero to vk, but intuitively vk will kind of later, and then when this edge gets visited, this will be an ancestor and it will be a back edge. Of course, we may not start a search here, so calling it the start of the search is not quite right, a little different. First vertex that gets hit. First vertex that gets hit, good. I am going to start the numbering, v zero, let is assume v zero is the first vertex in the cycle, visited by the depth first search. Together, if you want some pillows if you like them, especially convenient that they are in front. So right, if it is not v zero, say v3 was the first one visited. We will just change the labeling, so that is v zero, that is v1, that is v, and so on. So set this labeling, so that v0 first one, first vertex that gets visited. Then, I claim that let me just write the claim first. This edge vkv0 will be a back edge. We will just say, is back edge. And I would say this is not obvious, be a little careful. We have to somehow exploit the depth first nature of DFS, the fact that it goes deep it goes as deep as it can before backtracking. If you think about it, we are starting, at this point we are starting a search relative to this cycle. No one has been visited, except v zero just got visited, has a parent pointer off somewhere else. What do we do next? Well, we visit all the outgoing edges from v zero, there might be many of them. it could be edge from v zero to v1, it could an edge from v zero to v3, it could be an edge from v zero to something else. We do not know which one is going to happen first. But the one thing I can claim is that v1 will be visited before we finish visiting v zero. From v zero, we might go somewhere else, we might go somewhere else that might eventually lead to v1 by some other route, but in particular, we look at that edge from v zero to v1. And so, at some point, we are searching, we are visiting all the things reachable from v zero, that includes v1, and that will happen, we will touch v1 for the first time, because it has not been touched yet. We will visit it before we finish visiting v zero. The same goes actually for all of v i is, because they are all reachable from v zero. You can prove this by induction. You will have to visit v1 before you finish visiting v zero. You will have to visit v2 before you finish visiting v1, although you might actually visit v2 before v1. You would definitely finish, you will finished v2 before you finish v1, and so on. So vi will be visited before you finish vi minus 1, but in particular, what we care about is that vk is visited before we finish v zero. And it will be entirely visited. We will finish visiting vk before we finish visiting v zero. We will start decay vk after we start to v zero, because v zero is first. So the order is going to look like, start v zero, at some point we will start vk. Then we will finish vk, then we will finish v zero. This is something the textbook likes to call, and I like to call, balanced parentheses. You can think of it as, we start v zero, then we start vk, then we finish vk, then we finish v zero. And these match up and their balanced. Depth first search always looks like that, because once you start a vertex, you keep chugging until you visited all the things reachable from it. Then you finish it. You wo not finish v zero before you finish vk, because it is part of the recursion. You ca not return at a higher level before you return at the lower levels. So we have just argued that the order is like this, because v zero was first, so vk starts after v zero, and also we are going to finish vk before we finish v zero, because it is reachable, and has not been visited before. So, in here, we consider vkv zero. When we consider that edge, it will be a back edge. Why? Because v zero is currently on the recursion stack, and so you will have marked v zero as currently in process. So when you look at that edge, you see it is a back edge, it is an edge to your ancestor. That is the proof. Any questions about that? It is pretty easy once you set up the starting point, which is look at the first time you visit the cycle, than just think about how you walk around the cycle. There is lots of ways you might walk around the cycle, but it is guaranteed you will visit vk at some point, then you will look at the edge. v0 is still in the stack, so it is a back edge. And so this proves that having a cycle is equivalent to having a back edge. This gives you an easy linear time algorithm to tell, does my graph have a cycle? And if it does, it is actually easy to find one, because we find a back edge, just follow the tree edges, and you get your cycle. So if someone gives you a graph and say, hey, I think this is acyclic, you can very quickly say, no, it is not, here is a cycle, or say, yeah, I agree, no back edges, I only have tree, forward, and cross edges. OK, that was application one point Application two is topological sort, which we are going to think about in the setting of a problem called job scheduling. So job scheduling, we are given a directed acyclic graph. I want to order the vertices so that all edges point from lower order to high order. Directed acyclic graph is called a DAG, you should know that from forty two point And maybe I will draw one for kicks. Now, I have drawn the graph so all the edges go left to right, so you can see that there is no cycles here, but generally you had run DFS and you had detect there is no cycles. And now, imagine these vertices represent things you need to do. The textbook has a funny example where you are getting dressed, so you have these constraints that say, well, I have got to put my socks on before put my shoes on. And then I have got to put my underwear on before I put my pants on, and all these kinds of things. You would code that as a directed acyclic graph. You hope there is no cycles, because then you ca not get dressed. And there is some things, like, well, I could put my glasses on whenever, although actually I should put my glasses on before I do anything else, otherwise there is problems. I do not know, you could put your watch on at any time, unless you need to know what time is. So there is some disconnected parts, whatever. There is some unrelated things, like, I do not care the order between my shirt and my pants or whatever, some things are not constrained. What you had like to do is choose an actual order to do things. Say you are a sequential being, you can only do one thing at a time, so I want to compute a total order. First I will do g, then I will do a, then I can do h, because I have done both of the predecessors. Then I ca not do be, because I have not done d, so maybe I will do d first, and then b, and than e, then c, then f, then i. That would be a valid order, because all edges point from an earlier number to a later number. So that is the goal. And these are real job scheduling problems that come up, you will see more applications in your problem set. How do we do this? Well, at this point we have two algorithms, and I pretty much revealed it is DFS. DFS will do this. It is a topological sort, is what this algorithm is usually called. Topological sort because you are given a graph, which you could think of as a topology. You want to sort it, in a certain sense. It is not like sorting numbers, it is sorting vertices in a graph, so, hence, topological sort. That is the name of the algorithm. And it is run DFS, and output the reverse of the finishing times of vertices. so this is another application where you really want to visit all the vertices in the graph, so we use this top level DFS, so everybody gets visited. And there are these finishing times, so every time I finish a vertex, I could add it to a list. Say OK, that one was finished next, than this one is finished, than this one is finished. I take that order and I reverse it. That will be a topological order. Why? Who knows. Let is prove it. We have actually done pretty much the hard work, which is to say we are assuming our graph has no cycles, so that tells us by this cycle detection that there are no back edges. Back edges are kind of the annoying part. Now they do not exist here. So all the edges are tree edges, forward edges, and cross edges, and we use that to prove the theorem. So we want to prove that all the edges point from an earlier number to a later number. So what that means is for an edge, uv, we want to show that v finishes before u. That is the reverse, because what we are taking is the reverse of the finishing order. So edge uv, I want to make sure v finishes first, so that u will be ordered first. Well, there are two cases. Case one is that u starts before v. Case two is that he v before u. At some point they start, because we visit the whole graph. This top loop guarantees that. So consider what order we visit them first, at the beginning, and then we will think about how they finish. Well, this case is kind of something we have seen before. We visit u, we have not yet visited v, but v is reachable from u, so maybe via this edge, or maybe via some other path, we will eventually visit v in the recursion for u. So before u finishes, we will visit v, visit v before u finishes. That sentence is just like this sentence, so same kind of argument. We wo not go into detail, because we already did that several times. So that means we will visit v, we will completely visit v, we will finish v before we finish u and that is what we wanted to prove. So in that case is good. The other cases is that v starts before u. Here, you might get slightly worried. So we have an edge, uv, still, same direction. But now we start at v, u has not yet been visited. Well, now we worry that we visit u. If we visit u, we are going to finish u before we finish v, but we want it to be the other way around. Why ca not that happen? . Because there is a back edge somewhere here. In particular, the graph would have to be cyclic. This is a cycle, so this ca not happen, a contradiction. So v will finish before we visit u at all. So v will still finish first, because we do not even touch u, because there is no cycles. So that is actually the proof that topological sort gives you a valid job schedule, and it is kind of there are even more things you can do with DFS. We will see some in recitations, more in the textbook. But simple algorithm, can do a lot of nifty things with it, very fast, linear time. 
</body>
</html>