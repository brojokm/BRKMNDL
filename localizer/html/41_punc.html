<html>
<body>
So you guys might have heard, we have a quiz tomorrow. So we are going to do a review for that. Did everyone turn in P set six? Yes? Good. All right, so what is on this quiz? Numerics and graph stuff. So are there any specific pain points? I have problems prepared. Now, and then at 800 PM is going to be a review session for concepts. So now problems, 800 PM concepts, tomorrow? Yakim? has office hours at 500 PM, conveniently placed before the quiz. Poor guy. So take advantage of that. So yeah. Numerics, on P set we were mostly asked you said five, four, whichever came before. You mostly asked for the running times and things like that. But the numeric lecture notes are kind of detailed and go into Newtonian method and all that. How much detail do we need to know? So on the P set we make your life easier by giving you the pseudocode of the code that you needed to implement. And we ask you one algorithm design question, the problem of finding the k th root. And that required you to understand almost everything that was going on. We will want you to understand things that are going on to come up with something fairly similar to what you have seen. So yeah, I know that I told you guys before that ignore numerics. Just close your eyes and pretend it did not happen. Actually it turns out there is a significant amount of numerics on the quiz. So we are going to start with a numerics problem, and go through it. I am really sorry about that. Clearly I did not have my way for this, right? OK so we started two big things in numerics. Karatsuba, which is really easy compared to Newton which requires a lot of understanding. So we are going to spend our time on Newton today. OK, so anything aside from that? Yes. The thing we were just talking about before you were here was what kind of edges are produced by depth first search versus breadth first search? And why do they matter? And why do they matter. OK. Because it is probably going to be a question on the So I am going to go on this very quickly now, because I want to cover problems, but tonight this is on the outline for the review. So if you guys can make it tonight It is late, so I ca not make it. Sorry. Well, they are also in the lecture notes. But I will go through them very quickly now. OK, anything else? Making trees with DFS and BFS, this might be tonight also. Making trees Or your search trees. So instead of do you know what I mean by that? Do you mean graph transformation? So you have got a tree and you search through it. So then when you are searching through it, the result of searching it, you can put that into almost a binary tree. OK so how BFS and DFS work and how they produce trees, I am assuming, right? Because if you start out with a tree, everything is going to be really nice and simple. Right. Yes? Bidirectional search. OK. Is that going to be included? At a very conceptual level because we did not give you a P set on it. Was that what rubrics was? Yeah. It was bidirectional? Well it is not going to be on it so, we are happy. Well I mean we did not give you you kind of had to solve a problem just by we have to tell you this is bidirectional BFS, go code it up. This is bi directional Dijkstra, go code it up. So we are not going to ask you anything too fancy on them. So nothing past the P set. Will you have a question like when you were studying BFS, saying how there will be levels of graphs? Yep. Could there be anything about that? So levels of graphs as in the levels in BFS? Or the levels that we are using when we are building graphs? Copies of graphs and then Transformations. Yep. OK, transformations and layers. Yeah, I think this is important. Any particular tips on what kind of transformations we might encounter? Sure. Problem one has this transformation, problem two AUDIENCE LAUGHTER Basically, when do we use these? Is it when we are given more than one parameter for a cause. So I have some problems on this but we have to have a deal. You guys have to help me go through the problems fast enough so that we get here. OK? So if you know the answer, say the answer. Do not let me wait. OK. Also, when you run Dijkstra and Bellman Ford on a graph, with positive edges, they produce the same shortest path weight but might have different trees? Yes, that is conceivable. Because they It is one of the questions on spring two thousand and eleven point OK. So first off, they both have positive edges, so they both work, right? If you had to choose, which one would you choose? If you had to choose which are going to run, which one would you run? Dijkstra. OK, why Dijkstra? It is faster. Faster. OK so positive edges, Dijkstra is faster. Now if you are going to run both of them, they relax edges in different orders. Right? So let is say we have this. I know you guys remember the sequence of diamonds, right? My nice example that shows that the number of paths in a graph is exponential in the number of vertices. So let is have one diamond. 1, 1, 1, one point S, A, B, T. So say we are looking for shortest path from S. Right? So the distance from S to S is zero, and everything else starts out as infinity. SA is infinity. SB is infinity. ST is infinity. Suppose I relax edges in this order. One, two, three, four. What am I going to get? If I relax SA, then the distance from S to A is going to become 1, right? Because it is zero plus one one point And then the parent of A is going to be S. Now say I relax AT. The distance from S to T is going to be two point Sorry. Parent of T is going to be A. Right? OK now I am relaxing this one. This is going to become one and the parent of B is going to become S. And as I am relaxing this one, nothing happens because I already had a distance of two point Now if I relax them in this order instead, so the bottom one first and the top one is afterwards, I am going to get the different path. Right? OK so what path do I have now from S to T? Right now you have SAT. OK, why SAT? How do you compute the path? Parent pointers, right? Start at T, look at the parent pointer. Look at the parent pointer. So because I relax them in this order, this path was considered before this path. So the parent pointer of T is A but if I relax them in the other order, the parent pointer could be B. So by the way, this could happen if you are running Dijkstra or Bellman Ford. Or if you are running Dijkstra, it is just about how you are going to have the ties separated. So your priority queue implementation might give you different paths. Does it make sense now? So if the order in which edges are relaxed. That is what defines with path you are going to end up with. OK. OK. Hopefully useful. All right. I saw four hands before. Oh, just overall, how similar is this test compared to previous tests? Less algorithm design, more concepts. Nice. Yes. Well OK, not less algorithm so it is not going to be as much out of the box thinking, it is going to be a lot more of what we drilled already. So as a hint, what kind of problem did we practice over, and over, and over? States OK. Graph transformation, right? So chances are you will see that. Wait, what is graph transformation?  So we start with a complicated problem and reduce it to a shortest path problem or to a shortest length path problem. OK. Cool. So that being said, let is go. Numerics, everyone is favorite topic. So suppose we are trying to compute this. Cube root of 6,006. And the problem statement says this, you start out with an initial approximation of one, and it wants two approximations after that. The problem also tells you which function we are going to use. But why do not we make this fun and try to guess what the function will be? x cubed minus 6,006? OK. x cubed minus 6,006 why did I choose this function? Well, not me. Why did you choose this function? It is the root. OK so reason number one right? Important. Has to be zero at the answer, because that is what Newton is method gives us. And what else? Multiplication is easy. OK. So it is easy to compute whatever Newton is method wants us to compute. What does Newton is method want us to compute? So given an approximation, xi, how do we get to the next approximation, xi plus one point Formula. By the way, this formula should be on your cheat sheets. If it is not, no sympathy for you. I do not remember. xi plus f over f prime. Where is the prime? Prime is on the bottom. So yeah, where is the prime? And is this right? Is not there a constant? Is not it minus? Is not it minus? Maybe. There you go. So yeah, if you guys start out with the wrong formula you had get the wrong answer. Again, no sympathy. So get that on your sheets. OK so this is what we need to compute, right? You start with an approximation and you have to subtract this. So this has to be easy to compute. What if I chose instead a very nice function. x sorry, x minus. This is clearly zero where I want it to be, right? But we do not know what six But if I am trying to compute the successive approximations, very good, I am getting what? f of x over f prime of x is x minus square root three 6,006 over what is the derivative of this? One. One. So I have not done anything, right? In order to compute the successive approximation, I have to know this number. So this does not get me anywhere, that is why it is a bad function. By the way, it is not enough that this is easy to compute. What you want is this guy has to be easy to compute. In the case of division, we had a function that looked pretty wacky. But then when we divided that by the derivative, we got something reasonably nice. So this has to be easy to compute. So we changed it from that one to this one just because this one is easier or So we are using this one because this one let is see how easy this one is to compute. Computing this one requires that you know the answer to your original problem, which is not cool. Right. So you are trying to compute this number. But if you use this, Newton is approximation requires that you compute this. So you have to know this here. Which is what you are trying to do in the first place. Wait, I am confused. We went from x cubed minus six over six to x minus cube root of six over six point So what is your So this is a good function. We can use this. This is a bad function and I was asking why is this a bad function. Oh, OK. OK. So lets see, if we try to compute it using this, what do we get? xi minus x cubed minus 6,006. X cubed minus 6,006. Divided by 3x cubed. OK. So someone simplify this for me. 6i minus x over three plus 6,006 over three squared. Oh, well. It is 2,002. I will choose the easy step. OK. So what is x1? You plug in x0. OK. I heard a 2,002. I do not think it is it is very close. 2,002 and two thirds. 0. 67. OK, cool. So 0. 67, let is get to that later. I do not like fractional numbers. I mean this is the right answer math wise, but we will get to that because if we want to code this up, we probably do not want fractional numbers. So very good point there. What if I want to compute x2? I take this guy and I plug it into where? This thing over here, right? So this way I can compute approximations that get closer and closer to my original value. OK. Does this ring a bell? Yes, everyone is happy with this? Cool. So how about the initial guess? Here we started with a known initial guess. Is this a good guess? It is a really bad guess. 2,002? No, I mean one point 1? That is also a really bad guess. Why would you even ask? eleven and a half. All right. So you are saying eleven and a half would be a nice guess. So, first off, let is see, what do we need to what does Newton is algorithm guarantee? What if the guess is really, really bad, would we get an answer all the time? Maybe takes forever but we will get an answer. True or false? True. Not true. Sorry. But it has to be right for your answer to be OK, so what does Newton is method guarantee? INTERPOSING VOICES Yep, yep. So what is the fancy math name for that? Quadratic convergence or something. Quadratic convergence, all right. So this is what Newton guarantees. Quadratic so what does this mean? For all your approximations, they are all going to be xi. If we write them as true answer times one plus error, i. So this error is the relative error of the approximation. Newtons method guarantees that the error at each step is squared. So if this guy if E0 is greater than 1, would we get an answer? No. OK so what we need? What is the minimum that we need? E0 has to be between what and what? Negative 1? Is it negative 1, one or zero and 1? It would be zero and 1, right? Because wo not it be less than one? Negative one point Oh, absolute value. I think if you score something smaller than negative one you get a positive and then so, let is say this works. So then x0 has to be between what and what in relation to the real answer? The real answer minus x0 over. two times the actual answer is zero point OK so this is a sucky guess. We can do a lot better, but at least it will make the thing converge. Fair enough? OK now what if I want a good guess? First off, let is backtrack to a more general problem because this is easy, right? To plug it into our calculator and you have the answer. So what if I am trying to compute cube root of r. Can everyone see, by the way? Yes. Mhmm. OK. So I am trying to compute cube root of r. r is a number. Suppose I am trying to compute, for example, cube root of two point What is the first thing I need to do? I am going to code this up, by the way. Well, not me but suppose we want to code this up. What is the first thing we want to do? I think we want an initial guess at a function. OK so we are going to need an initial guess. That is good. And what else do we want? We need to decide how much precision we want. Yep. And why is that? Because this cube root of two is one point If you round down. That does not tell us very much. I do not know, we do not like the fractions. We do not like fractions. OK, why do not we like fractions? It is a lot easier to code. Decimal point there. Yep, you have to deal with the decimal point and we do not like that. So we want to take this problem, and we want to move it into integer land. So what we did here has fractions. We do not like that because that is a pain to code. We did not make you code fractions on the P set, right? So then we better know how to avoid fractions if you want to solve real life problems. So we are going to say that we are happy with some amount of precision in the answer. And then we are going to do something that lets us do all our computations in integer land. Because that is a happy place. So how do I suppose I am working in base B and I want d digits of precision. What do I want to compute? How do I transform the problem in that way? Yes? You multiply two root three times B to the d. OK so we want the answer to be two times B to the d. And if we are integer land, what are we actually going to get? So suppose B is ten let is work with familiar numbers d is two point So we are going to want to compute square root of three two times one hundred point Does anyone have a calculator and can tell me what square root of three is? First two digits? Cube root of two point Sorry, cube root of two point 1. 2. So let is say that square root of three is 1. 2345. Hopefully someone will fix this up for us. But let is say it is this. If I multiply it by one hundred what do I get? one hundred and twenty three times forty five point So multiply by one hundred means you move the decimal point to the right. Right? So it is still not an integer. If we work in integer land, our algorithm will return an integer. What is the integer that we are hoping our algorithm will return? 1. 23, right? We are hoping so, right? Why? What can you do with 123? Shift right. So if you divide this by 100, you get 1. 23. And this is our answer with two digits of precision. Do you want the actual it is 1. 2599. You guys are good. OK. So our algorithm will give us this, right? So it is not going to give us exactly cube root of two times one hundred point It is not going to give us exactly this value. What is it going to give us? Two digits close to that. So it is going to give us an integer, right? So what kind of integer? Math. Truncated? OK, what is the math for that? Truncated. Floor. Very good. So this is what we are actually going to compute. Actually, because we are in integer land, we are going to have floors at every step when we are doing that approximation. And there is a fancy proof for Newton that says that even though you are taking floors all the time, it will still converge to the right thing. So in order to compute this, how are we going to transform the problem? Slide the Bd into that. OK. You are going to have to put a three in there. B to the 3d. So we are actually going to compute cube root of two times B to the 3d. Fair enough? And if we slide this right by the digits afterwards we are going to get our two digits of precision. OK. So now I figured out my precision. I want an initial guess and actually I lied, there is one more problem. Running time. Do you guys want to start with the running time or initial guess? Initial guess. OK so what I want a good initial guess? Between zero and 2x. OK so if I do not have that the algorithm will crash and burn. When we did Newton in recitation, I said that I would like two things. And I backed up, I coded that into P set five when I did the guess. So what are the two things that I want from a good initial guess? Order of magnitude? OK. Perfect. Oh, god. LAUGHS OK, so order of magnitude is a fancy CSE way to say, right number of digits. Suppose we are computing this. Or suppose we are computing the cube root of some number in base B. So supposed r is somewhere between zero and B. It is one digit in base B. How many digits is this result is going to have? The amount of digits divided by three point The amount of digits in two times B to the 3d. Which is whatever B to the 3d is. D plus 1? OK so roughly either d or d plus one point See, d plus one point So a decent approximation would be a one followed by these zeros. An even better approximation is what if we can get the first digit right or almost right? How would we do that? Pick up the first digit of our r OK and I promise that r is one digit. Just So let is say we pick up r. And? We do Newtons method on that. And we just guess one? Is that a thing? Uhh Take the cube root of it. It should be some kind of inefficient Yeah what is some kind of inefficient way that we can think of quickly? Can you Binary? Did you say divide and divide it by 2r? Oh, sorry. I thought You were greater than you were going to say divide and conquer. So I heard binary search, so binary search wins. So we are going to the binary search. Binary search from zero to r. Right? In order to the binary search, suppose I have my guess, g, I want to see how g compares to cube root of r. How do I do this? So this is equivalent to g cubed compared to r. g cubed is to multiplication, so I know how to do that. OK? Make sense for everyone? Sorry, r. My bad. So this is going to be one digit in base, B, so hopefully not too much work. OK. But remember this, you cant do the comparison directly because you ca not compute this directly. So you need to do it this way. So r is just the first digit of the number? Yep. So we are going for a slightly easier problem. We are trying to compute the cube root of a single digit number to an arbitrary precision. You can make it harder, but there is no point right now. So we will stick to this. So how much time will this take? How many approximations will I need to do? By the way, so suppose I compute my approximations. Right? So I compute x0, x1, x2, x3, so on and so forth. When do I stop? When both digits are the same? All the digits are the same. So when one approximation is the same with the next one. That is what you are? Right. So these are all integers. The moment I get two identical integers, I know there is no point to continue because I am going to get the same value forever. Also this means that Newton is method has converged on this integer. So hopefully I will get the answer, which I can convert into the right answer. OK so how fast does this work? What is n? When am I going to stop? Log base two of d? OK. So n is so the number of digits in my approximation the number of correct digits doubles every time. So after log these steps, I have the right answer. Now what if instead of doing this I did binary search? So instead of doing Newton is method I do binary search on zero to r? I can do that, right? Because I can get a guess and then I can use this to see if my guess is right or wrong. So in theory I could do it in binary search. How fast would that be? And what is the difference between big r and little r? Big R is oh, I did not write the big r. Big r is this guy, here. Oh, OK, gotcha. OK. And this is little r. Sorry. Good question, I apologize for that. So R is little r times B to the 3d. D times log two of B To the d. Log r to the d. Oh, it is the same thing. Right. Yeah. On the y. OK so the number of guesses is Log big r. Log big r. And someone was one step ahead and said it is order of B times log little r. Or I think it is d plus little r. So this is order of d. Does this make sense for everyone? I did not quite follow what happened there. So I am doing a binary search on the range from zero to r. How many steps? How many guesses? Log r. Right? This is binary search. R is little r times b to the 3d. So if we log this, log R is log little r plus 3d log B. B is order one, so we get order of log B. OK so Newton is method is exponentially faster in terms of the number of digits compared to binary search. So if you can pull it off with Newton is method and you have big numbers, you probably want to use Newton is method. Because binary search will give you a slower algorithm. OK, how are we doing with these concepts? I see everyone is unhappy. Is it because of Newton or something I said? Can you summarize the difference between binary search and Newton is, again? So you said binary search takes kind of long versus Newton is method. OK. So how do you do binary search? Divide and conquer, which is Divide and conquer, right? You start out with an interval, you guess somewhere in half, and then you see which half of the interval you recurse onto. And your interval halves in size every time. So given the initial size of the interval, the number of guesses you have is log of that interval size. In this case we are guessing a number between zero and r. So the big goal is to compute cube root of R. And we are guessing that hey, it has to be somewhere between zero and R. So we are going to do binary search on this. And in order to see how our guess compares, we are going to use this trick, here. So the number of guesses we make is log R. Now R is that number, over there. It is little r times B to the 3d. So how many digits does it have? Roughly d digits. So log of R is going to be order d. OK so if you do binary search to guess a d digit number, the running time will be roughly order d. Order of the number of digits. If you use Newton is method and your function is good and everything converges, then you have quadratic convergence. Which guarantees that you will have log of d guesses. Log of d approximations. So Newton is method is a lot faster for big numbers, because you have a log there instead of d. So this is the big difference between them. But for Newton, you need a lot of things. Right? You need that function, you need an initial guess, you need a lot of things to make it work. Yes? So is that just like the number of times it runs? Because do not you have a multiplication and a division? Yep. So this is the number of guesses. The total running time is quite different. You need to jump through a few more hoops to analyze that. But this is the number of guesses or approximations that each method makes. So if your math would be order one, this would be the running time. If the math is not order one, then it gets more complicated. So what is the running time of a division? What is running time of the division using Newton is method? It is the same as the running time of the multiplication that you are using to compute your approximations. And it is like two pages of notes to prove that. So let is not go over that now. But the idea is that every time you are multiplying, you start multiplying small numbers and the numbers double in size when you are multiplying them. So only the last multiplication counts. All the others are tiny compared to that. OK. Anything else about Newton? Sorry guys, we have Newton on the exam so we have to go through this. Let is go through some fun graph problems. OK so we kicked off these two. Graphs the BFS edges and graph transformations. OK I am going to do a graph transformation first because I think that is more useful than BFS edges, but hopefully I am going to get to both. So suppose I have a graph. Each path is either red or blue. By the way, no political connection whatsoever. And you have weights on each path. So we want a path from S to T with the following constraint. So these weights are the costs of, maybe, how much gas you are spending to go on that road. So in order to switch from a red edge to a blue edge, you also have to pay some money. You have to pay a cost of five point So if you are going to go if you are going to go from S to A let is call this guy A if you are going to go this way, then your total cost is 3, 1, four point If you are going to go from S to B, then if you go this way, your total cost is going to be three plus one plus five for switching from a red to a blue edge. So the cost for switching from red to blue is five point The cost for switching from blue to red is five point And I will let you guys think of it for a bit while I erase the board. What is your goal in playing the best path from Best path from S to T. Smallest total cost. OK. So any thoughts? Yes. It is kind of on the run, but create a supernode connect all the red paths. And create another one connecting all the blue paths. And then try to find the shortest length to T just using those two graphs, I guess. So you are going to create a supernode connecting the paths. So how does this work? You create the path from S to T just using the reds. OK so I am going to copy everything and use the reds. So S, C, D, T, and I am only going to use the reds. All right, red, red, red. OK. And then wait, is that all the right paths? I hope so. All right, and then you are going to try doing that with the blue paths as well. So am I creating another copy of this? Yeah. OK. Let is see, what else, what else? OK From S to T, right? A path from S to T? Yeah, so you just compare the path of S to the path of T. So you completely take that out, the additional cost just by comparing those two and seeing which ones are the shortest path. It is correct for this graph, but it is not correct in general. INTERPOSING VOICES And the last option would be combining OK so if I do this so far. So I have taken the original graph and I have created two copies. One that has all of the red paths, one that has all the blue paths. Right. By the way, let is label this. The nodes are So it would work in this specific case because you. So if you compute the two shortest paths here, you will get the path using only reds, path using only blues. But you are not expressing the fact that you are allowed to alternate between reds and blues. How do you express that? Make a lot of corrections. Put two layers in Two layers. OK so these are two layers. This is the red layer, and this is the blue layer. And how do I connect them? If there is an edge connecting them on the upper graph, we are just connecting them. Or connect the respective nodes and make it a five point Both answers work, they have the same number of edges. The last answer is easier to visualize, so I am going to go with that. So I can go from the red world to the blue world, and back, if I am willing to pay five point So this is what And you just use those with the new edges. Or not DFS, but Dijkstra is. All right so all the edges here are positive, right? So I am going to use Dijkstra. Is there any case in a positive graph that Dijkstra is slower than Bellman Ford? Because one is like b log b, and the other one is like b e. Right? So if you have a lot of OK so what is Dijkstra? B log b Almost. T log b, I think, right? That is the theoretical best case ever, So actually, the theoretical is E plus Yeah, that is what I meant. Oh. Oh This is what you get with heaps, so this is what we got in the P set. What was the first one? The first one is like Fibonacci heaps. It is got a really high constant factor, so you never actually use it. So this is a nice theoretical thing, and this is what you get in practice. If you use the regular binary heaps. And so you compare this to Bellman Ford which is whoops V times E. I am going to guess that this is faster no matter what. Yes, OK. So the theoretical one could be slower, then, possible. The Fibonacci one? Because if you have a ton of vertices without many edges. OK If you have a ton of vertices but not too many edges. Yeah. Then you are saying that this is going to be bigger than so what do you do in that case? I mean you could just ignore the vertices, I guess. OK so if you have a ton of vertices and not that many edges. So if you have edges smaller sorry yeah, it is just smaller than vertices, then some vertices have to be unconnected. So what to do? You just ignore them. You are not going to reach them anyway. How do you ignore them? How do you ignore them in Oh, I see your point. So you are never going to get to them anyways. So Well no, but once you have started at one, you are going to have to touch them all. They are all going to be in the heap. Yeah. No, do not put them in the heap until you look at them. Well, there is a starting point, right? If you ca not go anywhere in the starting point, you are done. OK so you take the starting point and you do INTERPOSING VOICES Ok so I would take the starting point and do a BFS and ignore everything else. And that is clearly order of how many vertices and edges that are reachable from that. So that will give you a nice graph. Either that, or if you initialization your Dijkstra carefully enough, this actually only reflects the reachable edges and vertices. So you never have this. So either one works. In theory mode, it might be better to say I will do a BFS and reduce the graph. Because that is easier to argue. Yes. So, for this, when you make all that I guess my question is are we going to be asked to talk about running times for different transformation? Or the algorithms? Well so at the very least, last time we said, this is the problem. Give us an algorithm with this running time. Right. So you have to be able to know your transformations. So not the running for computing the transformation, but you have to be able to know how much bigger the graph gets and what that implies for the running time. Turns out that usually for these transformations you can compute them in linear time. So the time for computing a transformation is much smaller than the time for running Dijkstra or Bellman Ford. So that is why we do not really go into that. This one is definitely linear time. So what happens to the graph in this case? Number of edges and number of vertices. Number of edges increases by V and number of vertices. So increase by V. That is V, and times is two point So you plug this into Bellman Ford or Dijkstra, you find out the new running time. So every time you see what is the size of your new graph, and you plug that into the algorithm. OK so what is the intuition behind this? Did everyone get this problem? So it is the old problem that we are going through again and again, where you have a graph that is 2D, and we want to compute something that Dijkstra ca not compute on it is own. Or that Bellman Ford ca not compute on it is own. So in order to be able to compute those things, we need to add additional states to the graph. And the way we do that is we make copies of the graph that we call layers. Because we are thinking that if you take that 2D map, and you create copies of it, you basically have a 3D graph where there is the original graph. That is the science part of the problem, the art part of solving the problem is figuring out what those layers are and how you connect them. Because by doing that you can solve a ton of problems, as we have seen in this class. Is there a possibility that you have a very large number of layers needed to be permutations of different choice to make instead of just a red or a blue? Yep. So is there a problem where we had a ton of layers? Mhmm. Yep. OK so two problems, right? One for every second. LAUGHS And so these are the layers, presumably. We had two problems that had a ton of layers. One of them was the highway problem where you had timetables. And there, the number of layers was the number of minutes in the day you are considering. So roughly, one thousand, four hundred and forty point And the other one was StarCraft where the number of layers was something ginormous, right? So as long as that fits the theory, that is fine. As long as the number of layers fits whatever the problem wants you to compute, its OK. So transforming another layer, is that like in V time because copying the number of vertices? Yeah, so you should be able to implement this in order of V plus E, which is what you need to output the new graph description. I claim that for this you can. So for E prime, I guess, how had you get that? So for each vertex you are going to create a red copy and a blue copy. 2V, this is easy. Now, the red edges stay in here, the blue edges stay in here. So nothing changed so far. But each red vertex needs to be connected to the blue vertex by an edge of weight five point So that means that we are going to copy over the original edges and we are going to add the edges that connect the vertices. . So we are not going to ask about the running time of the transformations in general. Because we assume that they can be done in linear time. But you need to at least have a sense of whether your graph is going to double, whether it is going to increase exponentially, or what is going to happen to it. So let is make a small tweak to this problem. Suppose that the instead of having this, I can go from red to blue, but once I have gone from red to blue, I ca not go back. So I can start out either red or blue, I can go red to blue, but once I am in blue I ca not go back to red. Make those directed edges. From where to where? Red to blue. OK so this is how I express constraints, in constraints among layers. Before, we had two layers, red and blue. And we connected them by an edge of weight 5, which says you can go from red world to blue world, and back, all you have to do is pay five point If we have directed edges, then this is a constraint. If the constraint said there is no cost, but you can only go from red to blue, you still have to do two layers. And keep track of which layer you are in. But then your edge of the weight zero point Since we have to pay, the edge is weight five point So we can use layers to express additional costs, or just to express constraints. Does this make sense? Does this include back edges, or forward edges, as well? Let is get to that. OK, so does this make sense so far? One more question, what shortest path do I want to compute here? To make sure that you guys got it. Oh, you have to do two of them maybe, four OK, I like four of them. So I have to do SR, TR, SR, TB, SB, TR, SB, TB. Fortunately, our algorithms give us the shortest path from one source to all of the other vertices. So I had only have to run Dijkstra or Bellman Ford twice. What if I want to run the algorithm once? What do I do? You put vertices on the edges. OK so supernode as a source, supernode as a destination. And I connect them to what? Zero weight. To? The two. Final V. OK, very good. And? Same. So what happened here? This says you can go anywhere. And this says you can come back from anywhere. Bridge between the worlds. Yep. AUDIENCE LAUGHING So do we want this to be directed or undirected, by the way, does it matter? Directed. You can only go one way Oh, depends on which problem you are talking about. I think if they are undirected, it should not matter too much, because there should not be a path where you go back to the source and then you switch. But this would be if you are on a quiz and you do not want to think about that, I had make them directed just to be on the safe side. What were the four shortest paths you said we needed to calculate for the original problem, before you added the supernodes? So we do not know whether we start out with a red edge Right. with a blue edge. We do not know whether we end up with a red edge or a blue edge. Stay in red world, stay in blue world, red to blue and blue to red. Yeah OK, cool. So let is talk about BFS and DFS very briefly, I guess. So BFS and DFS. What does BFS give us? Why is it useful? Shortest paths. Shortest paths in terms of number of edges, right? No weight on the engines. So shortest paths using the number of edges. What does DFS give us? Topological start. Hey, man, you had this on the P set, I would not call it nothing. OK, how does BFS look at the graph? How does it partition the graph? Nodes are grouped into Levels. Levels. The light distance and the source. So you start with a source, and then all the nodes that are one edge away are at level one, all the nodes that are two edges away are level two, so on and so forth. What does DFS give us? A mess? A mess, right? So it gives us edge types. And it gives us exit times. Exit times are useful for topological sort, right? Yes. It also gives us a tree. OK, does BFS give us a tree? Yes. Yes, they both give us trees. So both of them will give us trees. So what are those trees? For each node, BFS or DFS discovered that node by going from some parent node across an edge. So that edge belongs to the BFS or to the DFS tree. How do we compute those trees? Just do it? So how do you, in BFS and DFS, what do you compute to Parent pointers? Parent pointers. So that is what you use to keep track of them. Sorry the question is bad but that is what I want you to get out of it. Parent pointers. So DFS and BFS will both compute trees of the graph. Are they the same trees or different trees? Probably different. Different trees, right? Let is take this. S, A, B, right? BFS will give us this, DFS will give us this. OK, what edge types do we have in DFS? Forward edges. OK, forward. Cool. What are they? Those are just from parent to children that are being presented. OK. So, I do not know how else to put it. OK so you should have this on your cheat sheet, right? If nobody knows the answer, you should have it on your cheat sheet. So tree edges, the ones that show up in the DFS tree. Backwards edges, Cross edges. Cross edges. Forward edges. And forward edges. If your graph is undirected, what types of edges do you not have? Forward edges. Forward edges and backward edges. Or no, forward edges. OK. So this is a lecture notes, and we are going to go over them tonight. But if you ca not make it, they are in lecture notes. So you should have this on your cheat sheet if you do not know them. Right? Nobody answered today, so if you guys do not have them on your cheat sheet I will be upset. OK. Cool. More questions? Edges do not exist in BFS, edge types? DFS uses so out of BFS we get levels, and out DFS we get those edge types. Is there about the edge types? Some algorithms use them in their proofs. So the proof for topological sort uses the fact that in directed acyclic graphs, you wo not have some types of edges. For the other types of edges it argues that the order that you get from topological sort is the right order. So it is mostly theoretical but since we taught you about edge types, we might ask you about them. Yes. So does DFS actually is it able to distinguish between back crossing over, or is it only does it only see that the node has already been visited by something? So how would you make it distinguish between them? You have to, right? Because otherwise, why are we studying them? There has to be a way to distinguish between them. Because the DFS does recursive calls and you know where the back is. So let is do a DFS tree quickly. So suppose we went like this. And then like this, this, and then this. Sorry, I am trying really hard to make up an example on the spot such that I wo not discount myself. How do I get that, do you know? Maybe an edge from the second one to the last one on the right. Here? Yeah and this will be the arrowhead, and you can start from the second one. This one? Yeah. Would not that be a forward edge? OK Because it is downward Yeah, I like that. OK, I like that. OK so S, A, B, C, D, E. So assume this is the order that they listed in adjacency list. So let is label all of the edges. SA and SB are what? Forward edges. OK AC? Forward. CD? Forward. CE? Forward. OK, AE? Are not those tree edges? That is a forward edge. That took a while, guys. That took a while. It goes forward. Well no, forward means like you are skipping a generation. OK so the three edges.  So the three edges are the ones that DFS uses to go forward. So they are the ones that map the DFS calls. So how do we express that? So suppose you are at some node u, and you have an edge, uv. The parent of v is u. So you are at here, right now. OK, so v. parent has to be u. And? v is? Is it visited or not? It is a new vertex. It is not. So v is not visited yet. So this is a tree edge. Now let is compare this to a forward edge. So what happens to a forward edge? Parents of children Parent ancestors So you are at here right now. And you are looking at the edge uv. Right? so we are looking at the edge uv. uv would point downward in the tree. What is true about v. parent is u. No Not necessarily. OK. So v. parent is u. So it can be the parent, or the grandparent, or so u has to be somewhere up the tree. Right? So I can have a ton of dot parents here. There has to be more than one dot parent, right? Because otherwise we get tree edge. It ca not just be one parent. OK. So you had have to recurse up more than once. Yep. So for a node you go up until you find u, and if you found u, then it is a forward edge, otherwise, if you find the root of the tree then you give up. Well then it is a cross edge. If you go up and you get to the root but oh Yeah, so if you got to the root, it is not the forward edge. Right now we are looking at what does it mean. So you have to be somewhere around the ancestor chain of u, so if you keep following v is parents, you have to see u. If not, it is not the forward edge. OK. And when you see it, did you visit it or did you not visit it? Already visited. OK. So now we have two more edge types, we have back edges, and we have cross edges. Right? Show me a back edge here. DA. DA is a back edge. OK back edges are also reasonably easy. So let is do those. What is a back edge. So I am at u now. I am looking at the edge uv. It is a cycle. Node to ancestor. Sorry? It is a node to an ancestor. OK so who is who is ancestor? A is D is ancestor. V is u is ancestor. OK. So if I keep going, u. parent many times over, I should eventually see v. Uhh yeah. So the difference between this and this is who is who is parent? Wait, would not u be a parent of v? Because we did not go from A to C to D and then at D I realize that I can go to A, but I wo not go because it is already visited? Wait. But assuming that A is an ancestor of D. So A is an ancestor of D because by the time I got to D, I have already set the parent pointers for C and D. Yes. But wait. u. parent is v. Then u is A here and v is D here No u is D here. I am at u right now, so I am at D. And I am looking at the edge uv. Do we have a cross edge in here? Do we have a cross edge in here. Good question. What is the cross edge? C? OK so this guy is a cross edge. So what is the difference between a cross edge and a forward edge? CLASS MURMURS It is not an ancestor. Ancester goes up to S. So a cross edge is very close to a forward edge except u is not an ancestor of v. v in the DFS tree. OK?  Yep. Yep. So the only common ancestor between B and C is the source. OK so please get these conditions in the notes. So as a summary, if it is an edge that DFS uses, it is a tree edge. If it is going against the way of the DFS, it is a back edge. If it fast forwards in DFS, so instead of going one level down, it does multiple levels down, then it is a forward edge. And otherwise, it is weird edge so it is a cross edge. One way to look at it. Yeah. Is this only true because we were going alphabetically? Yeah, this depends on the order in which the nodes are listed in the adjacency list. So it could have been pretty different if we went from A to E? Oh Yeah, yeah. Yep. I am trying to solve this another way. The graph information Yeah would you say that is moderate or an easy example? The transformation. This is on the easy side. So look at the problems that we had so far. There are more problems in this review packet. There are like six, seven, eight problems. It is going to be online. It is the notes for this recitation. Sorry, bad name. So the notes for this recitation. This is on the easy side. The StarCraft problem, last time is on the insanely difficult side, so that is not going to happen. I so do not even get that. That is on the hard side. 
</body>
</html>