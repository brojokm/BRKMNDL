<html>
<body>
Today we are going to solve three problems, a problem called Parenthesization, a problem called Edit Distance, which is used in practice a lot, for things like comparing two strings of DNA, and a problem called Knapsack, just about how to pack your bags. And we are going to get a couple of general ideas, one is about how to deal with string problems in general with dynamic programming. The first two and our previous lecture are all about strings, certain sense or sequences, and we are going to introduce a new concept, kind of like polynomial time, but only kind of, sort of pseudo polynomial time. Remember, dynamic programming in five easy steps. You define what your sub problems are and count how many there are, to solve a sub problem, you guess some part of the solution, where there is not too many different possibilities for that guess. You count them, better be polynomial. Then you, using that guess this is sort of optional, but I think it is a useful way to think about things. You write a recurrence relating the solution to the subproblem you want to solve, in terms of smaller subproblem, something that you already know how to solve, but it is got to be within this list. And when you do that, you are going to get a min or a max of a bunch of options, those correspond to your guesses. And you get some running time, in order to compute that recurrence, ignoring the recursion, that is time for subproblem. Then, to make a dynamic program, you either just make that a recursive algorithm and memoize everything, or you write the bottom up version of the DP. They do exactly the same computations, more or less, and you need to check that this recurrence is acyclic, that you never end up depending on yourself, otherwise these will be infinite algorithms or incorrect algorithms. Either way is bad. From the bottom up, you really like to explicitly know a topological order on the subproblems, and that is usually pretty easy, but you have got make sure that it is acyclic. And then, to compute the running time of the algorithm, you just take the number of subproblems from part one and you multiply it by the time it takes per subproblem, ignoring recursion, in part three point That gives you your running time. I have written this formula by now three times are more, remember it. We use it all the time. And then you need to double check that you can actually solve the original problem you cared about, either it was one of your subproblems or a combination of them. So that is what we are going to do three times today. One of the hardest parts in dynamic programming is step 1, defining your subproblems. Usually if you do that right, it becomes with some practice, step two is pretty easy. Step one is really where most of the insight comes in, and step three is usually trivial, once you know one and two point Once you realize one and two will work, the recurrence is clear. So I want to give you some general tips for step 1, how to choose subproblems, and we are going to start with problems that involve strings or sequences as input, where the problem, the input to the problem is string or sequence. Last class we saw text justification, where the input was a sequence of words, and we saw Blackjack, where the input was a sequence of cards. Both of these are examples, and if you look at them, in both cases we used suffixes, what do I call it, x, as our subproblems. If x was our sequence, we did all the suffixes, I equals zero up to the length of the thing. So they are about n, n plus 1, such subproblems. This is good. Not very many of them, and usually if you are plucking things off the beginning of the string or of the sequence, then you will be left with the suffix. If you always are plucking from the beginning, you always have suffixes, you will stay in this class, and that is good, because you always want a recurrence that relates, in terms of the same subproblems that you know. Sometimes it does not work. Sometimes prefixes are more convenient. These are usually pretty much identical, but if you are plucking off from the end instead of the beginning, you will end up with prefixes, not suffixes. Both of these have linear size, so they are good news, quite efficient. Another possibility when that does not work, we are going to see an example of that today, is you do all substrings. So I do not mean subsequences, they have to be consecutive substrains, i through j. And now for all i and j. How many of these are there? For a string of length n? N squared. So this one is n squared, the others are linear. Out of room here. Theta n. So you obviously you prefer to use these subproblems because there is fewer of them, but if sometimes they do not work, then use this one, still polynomial, still pretty good. This will get you through most DP is. It is pretty simple, but very useful. Let me define the next problem we consider. For each of them we are going to go through the five steps. So the first problem for today is parenthesization. You are given an associative expression, and you want to evaluate it in some order. So I am going to for associative expression, I am going to think of matrix multiplication, and I probably want to start at zero. So let is say you have n matrices, you want to compute their product. So you remember matrix multiplication is not commutative, I ca not reorder these things. All I can do is, if I want to do it by sequence of pairwise multiplications, is I get to choose where the parentheses are, and do whatever I want for the parentheses, because it is associative. It does not matter where they go. Now it turns out if you use straightforward matrix multiplication, really any algorithm for matrix multiplication, it matters how you parenthesize. Some will be cheaper than others, and we can use dynamic programming to find out which is best. So let me draw a simple example. Suppose I have a column vector times a row vector times a column vector. And there are two ways to compute this product. One is like this, and the other is like this. If I compute the product this way, it is every row times every column, and then every row times every column, and every row times every column. This subresult is a square matrix, so if these are say everything here is n, and this will be an n by n matrix. Then we multiply it by a vector and this computation has to take, if you do it well, it will take theta n squared time, because I need to compute n squared values here, and then it is n squared to do this final multiplication. Versus if I do it this way, I take all the rows here, multiply them on all the columns here, it is a single number, and then I multiply by this column. This will take linear time. So this is better parenthesization than this one. Now, I do not even need to define in general for an x by y matrix, times a y by z matrix, you can think about the running time of that multiplication. Whatever the running time is, dynamic programming can solve this problem, as long as it only depends on the dimensions of the matrices that you are multiplying. So for this problem, there is going to be the issue of which subproblems we use. Now we have a sequence of matrices here, so we naturally think of these as subproblems, but before we get to the subproblems, let me ask you, what you think you should guess? Let is just say from the outset, if I give you this entire sequence, what feature of the solution of the optimal solution would you like to guess? Ca not know the whole solution, because there is exponentially many ways to parenthesize. What is one piece of it that you had like to guess that will make progress? Any idea? It is not so easy. Well, would not you need the last operation? What is the last operation we are going to do, exactly. You might call it the outermost multiplication or the last multiplication. So that is going to look like we somehow multiply a zero through ak minus 1, and then we somehow multiply aK through an minus 1, and this is the last one. So now we have two subproblems. Somehow we want to multiply this, somehow I mean, there is got to be some last thing you do. I do not know what it is, so just guess it. Try all possibilities for k, it is got to be one of them, take the best. If somehow we know the optimal way to do a0 to k minus one and the optimal way to ak to an minus 1, then we are golden. Now, this looks like a prefix, this looks like a suffix. So do you think we can just combine subproblems, suffixes and prefixes? How many people think yes? A few? How many people think no, OK, why? So, for example if you split, if you were to split, like? Yeah. The very next thing we are going to do is recurse on this subproblem, recurse on this subproblem. When we recurse here, we are going to split it into a0 to ak prime minus 1, and ak prime minus 1, or ak prime to ak minus one point We are going to consider all possible partitions, and this thing, from ak prime to ak minus 1, is not a prefix or a suffix. What is it? A substring. There is only one thing left. I claim these are usually enough, and in this case substrings will be enough. But this is how you can figure out that, ah, I am not staying within the family prefixes, I am not staying within the family suffixes. In general, you never use both of these together. If you are going to need both, you probably need substrings. So if just suffixes work, fine. If just prefixes work, fine, but otherwise you are probably going to need substrings. That is just a rule of thumb, of course. Cool. So, part one subproblem is going to be the optimal evaluation parenthesization of ai to aj minus one point So that is part of the problem here. We want to do a0 to n minus one point So in general, let is just take some substring in here and say, well what is the best way to multiply that, and that is the sorts of subproblems we are getting if we use this guess. And if you start with a substring and you do this, you will still remain within a substring, so actually I have to revise this slightly. Now we are going from ai to solve this subproblem, which is what we need to do in the guessing step, we start from ai, we go to some guest place, ak minus 1, then from ak up to aj minus one point This is the i colon j subproblem. So we guess some point in the middle, some choice for k. The number of choices for k is number of possible choices for this guess, so we have to try all of them, is like order j minus i plus one point I put order in case I am off by one or something. But in particular this is. And that is all we will need. So that is the guess. Now we go to step 3, which is the recurrence. And this we are going to do this over and over again. Hopefully by the end, it is really obvious how to do this recurrence. Let me just fix my notation, we are going to use dp, I believe. For whatever reason, in my notes I often write dp of ij. This is supposed to be the solution to the subproblem i colon j. I want to write it recursively, in terms of smaller subproblems, and I want to minimize the cost, so I am going to write a min overall. And for each choice of k, so there is going to be a for loop, I am going to use Python notation here with iterators. So k is going to be in the range, I think range ij is correct. I am going to double check there is no off by 1 is here. Says i plus 1j. I think that is probably right. Once I choose where k is, where I am going to split my multiplication, I do the cost for i up to k, that is the left multiplication, plus the cost for k up to j, plus so those are the two recursive multiplications. So then I also have to do this outermost one. So how much does that cost? Well, it is something, so cost of the product ai colon k times the product ak colon j. So I am assuming I can compute this cost, not even going to try to write down a general formula, you could do it, it is not hard, it is like xyz. For a standard matrix multiplication algorithm. But whatever algorithm you are using, assuming you could figure out the dimensions of this matrix, it does not matter how it is computed, the dimensions will always be the same. You compute the dimensions of this matrix that will result from that product, it is always going to be the first dimension here, with the last dimension there. And it is constant time, you know that. And then if you can figure out the cost of a multiplication in constant time, just knowing the dimensions of these matrices, then you could plug this in to this dynamic program, and you will get the optimal solution. This is magically considering all possible parenthesizations of these matrices, but magically it does it in polynomial time. Because the time for subproblem here We are spending constant time for each iteration of this for loop, because this is a constant time just computing the cost. These are free recursive calls, so it is dominated by the length of the for loop, which we already said was order n, so it is order n time for subproblem, ignoring recursions. And so when we put this together, the total time is going to be the number of some problems, which I did not write. The number of problems in step one is n squared, that is what we said over here, for substrings. So running time is number of subproblems, which is n squared, times linear for each, and so it is order n cubed, it is actually theta n cubed. So polynomial time, much better than trying all possible parenthesizations, they are about four to the n parenthesizations, that is a lot. Topological order here is a little more interesting, if you think about that. I can tell you, for suffixes, topological order is almost always right to left. And for prefixes, it is almost always left to right, for increasing i, decreasing i. For substrings, what do you think it is? Or for this situation in particular? In what order should I evaluate these subproblems? . This is the running time to determine the best way to multiply that is right. So yeah, it is worth checking, because we also have to do the multiplication. But if you imagine this n, the number of matrices you are multiplying is probably much smaller than their sizes. In that situation, this will be tiny, whereas the time to actually do the multiplication, that is what is being computed by the DP, hopefully that is much larger, otherwise you are kind of wasting your time doing the DP. But hey, at least you could tell somebody that you did it optimally. But it gets into a fun issue of cost of planning verses execution, but we are not really going to worry about that here. So, in what order should I evaluate this recurrence, in order to I want, when I am evaluating DP of ij, I have already done DP of ik and DP of kj, and this is what you need for bottom up execution. Yeah. Small to large. Small to large, exactly. We want to do increasing substring size. That is actually what we are always doing for all of those subproblems over there. When I say all suffixes, you go right to left. Well, that is because the rightmost suffix is nothing, and then you build up a larger and larger strings, same thing here. Exercise, try to draw the DAG for this picture. It is a little harder, but if you I mean you could basically imagine I will do it for you. Here is, let is say well, at the top there is everything, the longest substring, that would be from zero to n, that is everything. Then you are going to have n different ways to have substrings of, or actually just two different ways, to have a slightly smaller substring. At the bottom you have a bunch of substrings, which are the length zero ones, and in between, like in the middle here, you are going to have a much larger number. And all these edges are pointed up, so you can compute all the length zero ones without any dependencies and then just increasing in length. It is a little hard to see, but in each case Yeah, ah, interesting. This is a little harder to formulate as a regular shortest paths problem, because if you look at one of these nodes, it depends on two different values, and you have to take the sum of both of them. And then you also add the cost of that split. Cool. So this is the subproblem DAG, you could draw it, but this DP is not shortest paths in that DAG. So perhaps dynamic programming is not just shortest paths in a DAG, that is a new realization for me as of right now. OK. Some other things I forgot to do I did not specify the base case. The base case for that recurrence is when your string is of length zero or even of length 1, because when it is length 1, there is only one matrix, there is no multiplication to do, and so the cost is zero. So you have something like dp of i, i plus one equals zero. That is the base case. And then step 5, step five is what is the overall problem I want to solve, and that is just dp from zero to n, that is the whole string. Any questions about that DP? I did not write down, I did not write down a memoized recursive algorithm, you all know how to do that. Just do this for loop and put this inside, that would be the bottom up one, or just write this with memoization, that would be the recursive algorithm. It is totally easy once you have this recurrence. All right, good. How many people is this completely clear to? OK. How many people does it kind of make sense? And how many people it does not make sense at all? OK, good. Hopefully we are going to shift more towards the first category. It is a little magical, how this guessing works out, but I think the only way to really get it is to see more examples and write code to do it, that is the ladder is your problem set, examples is what we will do here. So next problem we are going to solve. Dynamic programming is one of these things that is really easy once you get it, but it takes a little while to get there. So edit distance, we are going to make things a little harder. Now we are going to be given two strings instead of just one. And I want to know the cheapest way to convert x into y. I am going to define what transform means. We are going to allow character edits. We want to transform this string x into string y, so what character edits are we allowed? Very simple, we are allowed to insert a character anywhere in the strength, we are allowed to delete a character anywhere in the string, and we are allowed to replace a character anywhere in the string, replace c with c prime. Now, you could do a replacement by deleting c and inserting c that is, one way to do it, but I am going to imagine that in general someone tells me how much each of these operations costs, and that cost may depend on the character you are inserting. So deleting a character and then inserting a different character will cost one thing. It will cost the sum of those two cost values. Replacing a character with another character might be cheaper. It depends. Someone gives me a little table, saying for this character, for letter a, it costs this much to insert, for letter b it costs this much to insert, this much to delete, and there is a little matrix for, if I want to convert an a into a b it costs this much to replace. Imagine, if you will, you are trying to do a spelling correction, someone is typing on a keyboard, and you have some model of, oh, well if I hit a, I might have meant to hit an s, because s is right next to an a, and that is an easy mistake to make if you are not touch typing, because it is on the same finger, or maybe you are shifted over by one. So you can come up with some cost models, someone could do a lot of work and research and whatnot and see what are typical typos, replacing one letter for another, and then associate some cost for each character, for each pair characters, what is the likelihood that that was the mistake? I call that the cost, that is the unlikeliness. And then you want to minimize the sum of costs, and so you want to find what was the least set of errors that would end up with this word instead of this word. You do that on all words of your dictionary and then you will find the one that was most likely what you meant to type. And insertions and deletions are, I did not hit the key hard enough, or I hit it twice, or accidentally hit a key because it was right next to another one, or whatever. OK, so this is used for spelling correction. It is used for comparing DNA sequences, and DNA sequences, if you have one strand of DNA, there is a lot of mutation some mutations are more likely than others. For example, c to a g mutation is more common than c to an a mutation, and so you give this replacement a high cost, you give this one a low cost, to represent this is more likely than this. And then at a distance will give your measure of how similar two DNA strings are evolutionarily. And you also get extra characters randomly inserted and deleted in mutation. So, it is a simplified model of what happens in mutation, but still it is used a lot. So all these are encompassed by edit distance. Another problem encompassed by edit distance is the longest common subsequence problem. And I have a fun example, which I spent some hours, way back when, coming up with. I ca not spell it, though. It is such a weird word. Hieroglyphology is an English word and Michelangelo is another English word, if you allow proper nouns, unlike Scrabble. So, think of these as strings. This is x, this is y. What is the longest common subsequence? So not substring, I get to choose I can drop any set of letters from x, drop any set of letters from y, and I want them to, in the end, be equal. It is a puzzle for you. While you are thinking about it, you can model this as an edit distance problem, you just define the cost of an insert or a delete to be 1, and the cost of a replace to be zero point So this is a c to c prime replacement. It is going to be zero if c equals c prime, and I guess zero otherwise. You just do not consider it in that situation. Can anyone find the longest common subsequence here? It is in English word, that is a hint. So if you do this you are, basically trying to minimize number of insertions and deletions. Insertions in x correspond to deletions in y, and deletions in x correspond to deletions in x. So this is the minimum number of deletions in both strings, so you end up with a common substring. Because replacement says, I do not pay anything if the characters match exactly, otherwise I pay everything. I had never want to do this, so if there is a mismatch I have to delete it. And so this model is the same thing as long as common subsequence. I want to solve this more general problem, it is actually easier to solve the more general problem, but in particular, you can use it to solve this tricky problem. Any answers? Yeah. Hello. Very good. Hello is the longest common subsequence. You can imagine how I found that. Searching for all English words that have hello as the subsequence. That can also be done in polynomial time. So how are we going to do this? Well, I had like to somehow use subproblems for strings, suffixes, prefixes, or substrings. But now I have two strings, that is kind of annoying. But do not worry, we can do sort of dynamic programming simultaneously over x and y. What we are going to do is look at suffixes of x and suffixes of y, and to make our subproblems we need to combine all of those subproblems by multiplication. We need to think about both of them simultaneously. So subproblem is going to be solve edit distance, edit distance problem on two different strings, a suffix of x and a possibly different suffix of y. Because this is for all possible i and j choices. And so the number of subproblems is? N squared. N squared, yes. If x is of length n and y is of length n, there is n choices for this, n choices for that, and we have to do all of them as pairs, if there is n squared pairs. In general, if they have different lengths, it is going to be the length of x times length of y. It is quadratic. Good. So, next we need to guess something, step two point This is maybe not so obvious, let is see. You have here is x, starting at position i. You have y starting at position j. Somehow I need to convert x into y, I think it is probably better if I line these up, even though in some sense they are not lined up, that is OK. I want to convert x into y. What should I look at here? Well, I should look at the very first characters, because we are looking at suffixes. We want to cut off first characters somehow. How could it what are the possible ways to convert, or to deal with the first character of x? What are the possible things I could do? Given that, ultimately, I want the first character of x to become the first character of y. Delete. You could delete this character and then insert this one, yes. Other things? There is a few possibilities. If you look at it right, there are three possibilities. And three possibilities are insert, delete, or replace. So let is figure out how that is the case. I could replace this character with that character, so that is one choice. That will make progress. Once I do that, I can cross off those first characters and deal with the rest of the substrings. Let is think about insert and delete. If I wanted to insert, presumably, I need this character at some point. So in order to make this character, if it is not going to come from replacing this one, it is got to be from inserting that character right there. Once I do that, I can cross out that newly inserted character in this one, and then I have all of the string x from i onward still, but then I have removed one character from y, so that is progress. The other possibility is deletion, so maybe I delete this character, and then maybe I insert it in the next step, but it could be this character matches that one, or maybe I have to delete several characters before I get to one that matches, something. But I do not know that, so that is hard to guess, because that would be more time to guess. But I could say, well, this character might get deleted. If it gets deleted, that is it, it gets deleted. And then somehow the rest of the x, from i plus one on, has to match with all of y, from j on. But those are the three possibilities, and in some sense capture all possibilities. So it could be we replace xi with yj, and so that has some cost, which we are given. It could be that we insert yj at the beginning, or it could be that we delete xi. You can see that is definitely spanning all the possible operations we can do, and if you think about it long enough, you will be convinced this really covers every possible thing you can do. If you think about the optimal solution, it is got to do something to make this first character. Either it does it by replacement or it does it by an insertion. But if it inserts it later on, it is got to get this out of the way somehow, and that is the deletion case. If it inserts it at the beginning, that is the insertion case, if it just does a replacement, that is the replace case. Those are all possibilities for the optimal solution. Then you can write a recurrence, which is just a max of those things, those three options. So I am going to write, I guess, dp of ij, yes, of i,j, but now i,j is not a substring. It is a suffix of x and a suffix of y, so it corresponds to this subproblem. If I want to solve that subproblem, it is going to be the min of three options. We have got the replace case, so it is going to be some cost of the replace, from xi to yj. So that is a quantity which we are given. Plus the cost of the rest. So after we do this replacement, we can cross off both those characters, and so we look at i plus one on for x, and j plus one onwards for y. So that is option one point Then comma for the min. Option two is we have the cost of insert yj. So that is also something we are given. Then we add on what we have to do afterwards, which is we have just gotten rid of yj, so x still has the entire string from i on, and y has a smaller string. Comma. Last option is basically the same, cost of the delete, deleting xi, and then we have to add on DP of i plus 1j. Because here we did not advance y but we advanced x. It is crucial that we always advance at least one of the strings, because that means we are making progress, and indeed, if you want to jump to step 4, which is topological ordering sorry, I reused my symbols here, some different symbols. Head back to step four of DP, topological order. Well, these are suffixes, and so I know with suffixes I like to go from the smaller suffixes, which is the end, to the beginning. And, indeed, because we are always increasing, we are always looking at later substrings, later suffixes, for one or the other. It is enough to just do come over here. To just do that for both of the strings, it does not really matter the order. So you can do for i equals x down to zero, for j equals y down to zero, and that will work. Now this is another dynamic programming you can think of as just shortest paths in the DAG. The DAG is most easily seen as a two dimensional matrix, where the i index is between zero and length of x, and the j index is between zero and length of y, and each of the cells in this matrix is a node in the DAG. That is one of our subproblems, dp of ij. And it depends on these three adjacent cells. The edges are like this. If you look at it, we have to check i plus 1, j plus 1, that is this guy. We have to check ij plus 1, that is this guy. We have to check i plus 1j, that is this guy. And so, as long as we compute the matrix this way, what I have done here is row by row, bottom up. You could do it anti diagonals, you could do it column by column backwards, all of those will work because we are making progress towards the origin. And so if you ever if you look up at a distance, most descriptions think about it in the matrix form, but I think it is easier to think of it in this recursive form, whatever your poison. But this is, again, shortest paths in a DAG. The original problem we care about is dp of zero zero, the upper left corner. So to be clear in the DAG, what you write here is like the cost of, the weight of that edge is the cost of, I believe, a deletion. Deletion, oh sorry, it is an insertion. Inserting that character, this one is a cost of deletion, this is a cost to replace, so you just put those edge weights in, and then just do a shortest paths in the DAG, I think, from this corner to this corner. And that will give you this, or you could just do this for loop and do that in the for loop, same thing. OK. What is the running time? Well, the number of subproblems here is x times y, the running time for subproblem is? I am assuming that I know these costs in constant time, so what is the overall running time of that, evaluating that? Constant. And so the overall running time is the number of subproblems times a constant equals x times y. This is the best known algorithm for edit distance, no one knows how to do any better. It is a big open problem whether you can. You can improve the space a little bit, because we really only need to store the last row or the last column, depending on the order you are evaluating things. To even get down to linear space, as far as we know, we need quadratic time. One more problem, are you ready? This one is going to blow your minds hopefully. Because we are going to diverge from strings and sequences, kind of. So far everything we have looked at involves one or two strings or sequences, except for. That involved a graph, that was a little more exciting. But we had already seen that, so it was not that exciting. OK, our last problem for today is knapsack. It is a practical problem. You are going camping. You are going backpacking, I should say, and you can only afford to take whatever you can fit on your back. You have some limit to capacity, let is say one giant backpack is all you can carry. Let is imagine it is the size of the backpack that matters, not the weight, but you could reformulate this in terms of weight. And you have got a lot of stuff you want to bring. Ideally you bring everything you own, that would be kind of nice, convenient, but it had be kind of heavy. So you are limited, you are not able to do that. So you have a list of items and each of them has a size, si, and has a desire, a value to you, how much you care about it, how much you need it on this trip. OK, each item has two things, and the sizes are integers. This is going to be important. It wo not work without that assumption. And we have a knapsack, backpack, whatever, I guess it is the British, but I do not know, I get confused. Growing up in Canada, I use both, so it is very confusing. Knapsack of total size, S. And what you had like to do is choose a subset of the items. If you are lucky, the sum of the si is fit within s, then you bring everything. But if you are not lucky, that is not possible, you want to choose a subset of the items whose total size is less than or equal to s, in order to maximize the sum of the values. So you want to maximize the sum of values for a subset of items, of total size less than or equal to S. You can imagine size as weights instead of size, not a big deal, or you could have sizes and weights. All of these things generalize. But we are going to need that the sizesweights are integers. And so the items have to fit, because you ca not cheat, you ca not have more things than what fit, but then you want to maximize the value. How do we do this with dynamic programming? With difficulty. I do not have a ton of time, so I think I am going to tell you well, let is see. Start with guessing. This is the easy part to this problem. We should also be thinking about subproblems at the same time. Even though I said we are leaving sequences, in fact, we have a sequence here, we have a sequence of items. We do not actually care about the order of the items, but hey, they are in an order. If they were not, we could put them in an order, in an arbitrary order. We are going to use that order, and we are going to look at suffixes of items. i colon of items. That is helpful, because now it says, oh, well, we should be plucking off items from the beginning. Starting with the i th item, what should I decide about the i th item, relative to the optimal solution? What should I guess? Is i included or not? Is i included or not, exactly. Is item i in the subset or not. Two choices, easy. Of course, those are the choices. If I do that for everybody, then I know the entire subset. Somehow I need to be able to write and this is what is actually impossible if I choose this as my subproblem. I want to write DP of i, somehow, in terms of, I guess, DP of i plus one point And we had like to do max, and either we do not put it in, in which case that is our value, or we put it in, in which case we get an additional v i in value. OK, but we consume in size, and there is no way to remember that we have consumed the size here. We just called DP of i plus one point In this case, it has everything, all this. In this case, we lose si of S, but we ca not represent that here. That is bad, this would be an incorrect algorithm. I would always choose to put everything in, because it is not keeping track of the size bound. There is no capital S in this formula, that is wrong. So, to fix that, I am going to write that again, but a subproblem is going to have more information, it is going to have an index i, and it is going to have remaining capacity. I am going to call it capital X, at some integer at most S. We are assuming that the sizes are all integers, so this is valid. The number of subproblems is equal to n, the number of items, did I say there are n items? Now there are n items, times capital S, really S plus 1, because I have to go down to zero. But n times S, different subproblems. Now for each of them I can write a recurrence, and that is DP of i comma s, is going to be the max of DP of i plus 1s. This is the case where we do not include the items, so S stays the same. Actually I should write x here, because it is not actually our original value of s. x is the general situation. The other possibility is we include item i, and then we give DP of i plus one point We still consume item i. We now have x minus si as our new capacity, what remains after we add in this item. And then we add on vi, because that is the value we gain from putting that item in. That is it, that is the DP, pretty simple. Let me say a little bit about the running time of this thing. Again, you check there is a topological order and all that, it is in the notes. The total running time, we spend constant time to evaluate this formula, so it is super easy. The number of subproblems is the bottleneck. So it is n times s. Is this polynomial time? You might guess from the outline of today that the answer is no. This is not polynomial time. What this polynomial time mean? It is polynomial and n, where n is the size of the input. What is the size of the input here? Well, we are given n items, each with a size, each with a value. If you think of the sizes and values as being single word items, then the size is n. If you think of them as being ginormous values, at most, the size of this input is going to be something like n times log s, because if you write it out in binary you would need log s, bits to write down those numbers. But it is not n times s. This would be the binary encoding of the input, but the running time is this. Now s is exponential in log s, this is, at best, an exponential time algorithm. But it is really not that bad if s is small, and so we call it pseudopolynomial time. What does pseudopolynomial mean? It just means that your polynomial in n, the input size, which might be this, and in the numbers that are in your input. Numbers here means integers, basically, otherwise it is not really well defined. So in this case we have a bunch of integers, but in particular we have s. And so there is S and the si is. This is definitely polynomial in n and s. It is the product of n and S. So you think of this as pseudoquadratic time, I guess? Because it is quadratic, but one of the things is pseudo, meaning it is one of the numbers in the input. So if the number is big in k bits, so I can write down a number that is of size two to the k. So it is kind of in between polynomial and exponential, you might say. Polynomial good, exponential bad, pseudopolynomial, it is all right. That is the lesson. And for knapsack, this is the best we can do, as we will talk about later. Pseudopolynomial is really the best you could hope for. So, sometimes that is as good as you can do and dynamic programming lets you do it. 
</body>
</html>