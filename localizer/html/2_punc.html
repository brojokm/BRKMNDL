<html>
<body>
Hey, everybody. You ready to learn some algorithms? Yeah Let is do it. I am Eric Domain. You can call me Eric. And the last class, we sort of jumped into things. We studied peak finding and looked at a bunch of algorithms for peak finding on your problem set. You have already seen a bunch more. And in this class, we are going to do some more algorithms. Do not worry. That will be at the end. We are going to talk about another problem, document distance, which will be a running example for a bunch of topics that we cover in this class. But before we go there, I wanted to take a step back and talk about, what actually is an algorithm? What is an algorithm allowed to do? And also deep philosophical questions like, what is time? What is the running time of an algorithm? How do we measure it? And what are the rules the game? For fun, I thought I would first mention where the word comes from, the word algorithm. It comes from this guy, a little hard to spell. Al Khwarizmi, who is sort of the father of algebra. He wrote this book called The Compendious Book on Calculation by Completion and Balancing back in the day. And it was in particular about how to solve linear and quadratic equations. So the beginning of algebra. I do not think he invented those techniques. But he was sort of the textbook writer who wrote sort of how people solved them. And you can think of how to solve those equations as early algorithms. First, you take this number. You multiply by this. You add it or you reduce to squares, whatever. So that is where the word algebra comes from and also where the word algorithm comes from. There are not very many words with these roots. So there you go. Some fun history. What is an algorithm? I will start with sort of some informal definitions and then the point of this lecture. And the idea of a model of computation is to formally specify what an algorithm is. I do not want to get super technical and formal here, but I want to give you some grounding so when we write Python code, when we write pseudocode, we have some idea what things actually cost. This is a new lecture. We have never done this before in six point But I think it is important. So at a high level, you can think of an algorithm is just a I am sure you have seen the definition before. It is a way to define computation or computational procedure for solving some problem. So whereas computer code, I mean, it could just be running in the background all the time doing whatever. An algorithm we think of as having some input and generating some output. Usually, it is to solve some problem. You want to know is this number prime, whatever. Question? Can you turn up the volume for your mic? This microphone does not feed into the AV system. So I shall just talk louder, OK? And quiet the set, please. OK, so that is an algorithm. You take some input. You run it through. You compute some output. Of course, computer code can do this too. An algorithm is basically the mathematical analog of a computer program. So if you want to reason about what computer programs do, you translate it into the world algorithms. And vice versa, you want to solve some problem first, you usually develop an algorithm using mathematics, using this class. And then you convert it into computer code. And this class is about that transition from one to the other. You can draw a picture of sort of analogs. So an algorithm is a mathematical analog of a computer program. A computer program is built on top of a programming language. And it is written in a programming language. The mathematical analog of a programming language, what we write algorithms in, usually we write them in pseudocode, which is basically another fancy word for structured English, good English, whatever you want to say. Of course, you could use another natural language. But the idea is, you need to express that algorithm in a way that people can understand and reason about formally. So that is the structured part. Pseudocode means lots of different things. It is just sort of an abstract how you would write down formal specification without necessarily being able to actually run it on a computer. Though there is a particular pseudocode in your textbook which you probably could run on a computer. A lot of it, anyway. But you do not have to use that version. It just makes sense to humans who do the mathematics. OK, and then ultimately, this program runs on a computer. You all have computers, probably in your pockets. There is an analog of a computer in the mathematical world. And that is the model of computation. And that is sort of the focus of the first part of this lecture. Model of computation says what your computer is allowed to do, what it can do in constant time, basically? And that is what I want to talk about here. So the model of computation specifies basically what operations you can do in an algorithm and how much they cost. This is the what is time. So for each operation, we are going to specify how much time it costs. Then the algorithm does a bunch of operations. They are combined together with control flow, for loops, if statements, stuff like that which we are not going to worry about too much. But obviously, we will use them a lot. And what we count is how much do each of the operations cost. You add them up. That is the total cost of your algorithm. So in particular, we care mostly in this class about running time. Each operation has a time cost. You add those up. That is running time of the algorithm. OK, so let is I am going to cover two models of computation which you can just think of as different ways of thinking. You have probably seen them in some sense as what you call them? Styles of programming. Object oriented style of programming, more assembly style of programming. There is lots of different styles of programming languages which I am not going to talk about here. But you have see analogs if you have seen those before. And these models really give you a way of structuring your thinking about how you write an algorithm. So they are the random access machine and the pointer machine. So we will start with random access machine, also known as the RAM. Can someone tell me what else RAM stands for? Random Access Memory? Random Access Memory. So this is both confusing but also convenience. Because RAM simultaneously stands for two things and they mean almost the same thing, but not quite. So I guess that is more confusing than useful. But there you go. So we have random access memory. Oh, look at that. Fits perfectly. And so we are thinking, this is a real this is random access memory is over here in real computer land. That is like, D RAM SD RAM, whatever the things you buy and stick into your motherboard, your GP, or whatever. And over here, the mathematical analog of so here is, it is a RAM. Here, it is also a RAM. Here, it is a random access machine. Here, it is a random access memory. It is technical detail. But the idea is, if you look at RAM that is in your computer, it is basically a giant array, right? You can go from zero to, I do not know. A typical chip these days is like four gigs in one thing. So you can go from zero to four gigs. You can access anything in the middle there in constant time. To access something, you need to know where it is. That is random access memory. So that is an array. So I will just draw a big picture. Here is an array. Now, RAM is usually organized by words. So these are a machine word, which we are going to put in this model. And then there is address zero, address one, address two. This is the fifth word. And just keeps going. You can think of this as infinite. Or the amount that you use, that is the space of your algorithm, if you care about storage space. So that is basically it. OK, now how do we this is the memory side of things. How do we actually compute with it? It is very simple. We just say, in constant time, an algorithm can basically read in or load a constant number of words from memory, do a constant number of computations on them, and then write them out. It is usually called store. OK, it needs to know where these words are. It accesses them by address. And so I guess I should write here you have a constant number of registers just hanging around. So you load some words into registers. You can do some computations on those registers. And then you can write them back, storing them in locations that are specified by your registers. So you have ever done assembly programming, this is what assembly programming is like. And it can be rather annoying to write algorithms in this model. But in some sense, it is reality. This is how we think about computers. If you ignore things like caches, this is an accurate model of computation that loading, computing, and storing all take roughly the same amount of time. They all take constant time. You can manipulate a whole word at a time. Now, what exactly is a word? You know, computers these days, it is like thirty two bits or sixty four bits. But we like to be a little bit more abstract. A word is w bits. It is slightly annoying. And most of this class, we wo not really worry about what w is. We will assume that we are given as input a bunch of things which are words. So for example, peak finding. We are given a matrix of numbers. We did not really say whether they are integers or floats or what. We do not worry about that. We just think of them as words and we assume that we can manipulate those words. In particular, given two numbers, we can compare them. Which is bigger? And so we can determine, is this cell in the matrix a peak by comparing it with its neighbors in constant time. We did not say why it was constant time to do that. But now you kind of know. If those things are all words and you can manipulate a constant number of words in constant time, you can tell whether a number is a peak in constant time. Some things like w should be at least log the size of memory. Because my word should be able to specify an index into this array. And we might use that someday. But basically, do not worry about it. Words are words. Words come in as inputs. You can manipulate them and you do not have to worry about it for the most part. In unit four of this class, we are going to talk about, what if we have really giant integers that do not fit in a word? How do we manipulate them? How do we add them, multiply them? So that is another topic. But most of this class, we will just assume everything we are given is one word. And it is easy to compute on. So this is a realistic model, more or less. And it is a powerful one. But a lot of the time, a lot of code just does not use arrays does not need it. Sometimes we need arrays, sometimes we do not. Sometimes you feel like a nut, sometimes you do not. So it is useful to think about somewhat more abstract models that are not quite as powerful but offer a simpler way of thinking about things. For example, in this model there is no dynamic memory allocation. You probably know you could implement dynamic memory allocation because real computers do it. But it is nice to think about a model where that is taken care of for you. It is kind of like a higher level programming abstraction. So the one is useful in this class is the pointer machine. This basically corresponds to object oriented programming in a simple, very simple version. So we have dynamically allocated objects. And an object has a constant number of fields. And a field is going to be either a word so you can think of this as, for example, storing an integer, one of the input objects or something you computed on it or a counter, all these sorts of things or a pointer. And that is where pointer machine gets its name. A pointer is something that points to another object or has a special value null, also known as nil, also known as none in Python. OK, how many people have heard about pointers before? Who has not? Willing to admit it? OK, only a few. That is good. You should have seen pointers. You may have heard them called references. Modern languages these days do not call them pointers because pointers are scary. But there is a very subtle difference between them. And this model actually really is references. But for whatever reason, it is called a pointer machine. It does not matter. The point is, you have seem linked lists I hope. And linked lists have a bunch of fields in each node. Maybe you have got a pointer to the previous element, a pointer to the next element, and some value. So here is a very simple linked list. This is what you had call a doubly linked list because it has previous and next pointers. So the next pointer points to this node. The previous pointer points to this node. Next pointer points to null. The previous pointer points to null, let is say. So that is a two node doubly linked list. You presume we have a pointer to the head of the list, maybe a pointer to the tail of list, whatever. So this is a structure in the pointer machine. It is a data structure. In Python, you might call this a named tuple, or it is just an object with three attributes, I guess, they are called in Python. So here we have the value. That is a word like an integer. And then some things can be pointers that point to other nodes. And you can create a new node. You can destroy a node. That is the dynamic memory allocation. In this model, yeah, pointers are pointers. You ca not touch them. Now, you can implement this model in a random access machine. A pointer becomes an index into this giant table. And that is more like the pointers in C if you have ever written C programs. Because then you can take a pointer and you can add one to it and go to the next thing after that. In this model, you can just follow a pointer. That is all you can do. OK, following a pointer costs constant time. Changing one of these fields costs constant time. All the usual things you might imagine doing to these objects take constant time. So it is actually a weaker model than this one. Because you could implement a pointer machine with a random access machine. But it offers a different way of thinking. A lot of data structures are built this way. Cool. So that is the theory side. What I had like to talk about next is actually in Python, what is a reasonable model of what is going on? So these are old models. This goes back to the 80s. This one probably 80s or 70s. So they have been around a long time. People have used them forever. Python is obviously much more recent, at least modern versions of Python. And it is the model of computation in some sense that we use in this class. Because we are implementing everything in Python. And Python offers both a random access machine perspective because it has arrays, and it offers a pointer machine perspective because it has references, because it has pointers. So you can do either one. But it also has a lot of operations. It does not just have load and store and follow pointer. It is got things like sort and append and concatenation of two lists and lots of things. And each of those has a cost associated with them. So whereas the random access machine and pointer machine, they are theoretical models. They are designed to be super simple. So it is clear that everything you do takes constant time. In Python, some of the operations you can do take a lot of time. Some of the operations in Python take exponential time to do. And you have got to know when you are writing your algorithms down either thinking in a Python model or your implementing your algorithms in actual Python, which operations are fast and which are slow. And that is what I had like to spend the next few minutes on. There is a lot of operations. I am not going to cover all of them. But we will cover more in recitation. And there is a whole bunch in my notes. I wo not get to all of them. So in Python, you can do random access style things. In Python, arrays are called lists, which is super confusing. But there you go. A list in Python is an array in real world. It is a super cool array, of course? And you can think of it as a list. But in terms implementation, it is implemented as an array. Question? I thought that. You thought Python links lists were linked lists. That is why it is so confusing. In fact, they are not. In, say, scheme, back in the days when we taught scheme, lists are linked lists. And it is very different. So when you do I will give an operation here. You have a list L, and you do something like this. L is a list object. This takes constant time. In a linked list, it would take linear time. Because we have got a scan to position I, scan to position J, add 5, and store. But conveniently in Python, this takes constant time. And that is important to know. I know that the terminology is super confusing. But blame the benevolent dictator for life. On the other hand, you can do style two, pointer machine, using object oriented programming, obviously. I will just mention that I am not really worrying about methods here. Because methods are just sort of a way of thinking about things, not super important from a cost standpoint. If your object has a constant number of attributes it ca not have like a million attributes or ca not have n executes then it fits into this pointer machine model. So if you have an object that only has like three things or ten things or whatever, that is a pointer machine. You can think of manipulating that object as taking constant time. If you are screwing around the object is dictionary and doing lots of crazy things, then you have to be careful about whether this remains true. But as long as you only have a reasonable number of attributes, this is all fair game. And so if you do something like, if you are implementing a linked list, Python I checked still does not have built in linked lists. They are pretty easy to build, though. You have a pointer. And you just say x equals x. next. That takes constant time because accessing this field in an object of constant size takes constant time. And we do not care what these constants are. That is the beauty of algorithms. Because we only care about scalability with n. There is no n here. This takes constant time. This takes constant time. No matter how big your linked list is or no matter how many objects you have, these are constant time. OK, let is do some harder ones, though. In general, the idea is, if you take an operation like L. append so you have a list. And you want to append some item to the list. It is an array, though. So think about it. The way to figure out how much does this cost is to think about how it is implemented in terms of these basic operations. So these are your sort of the core concept time things. Most everything can be reduced to thinking about this. But sometimes, it is less obvious. L. apend is a little tricky to think about. Because basically, you have an array of some size. And now you want to make an array one larger. And the obvious way to do that is to allocate a new array and copy all the elements. That would take linear time. Python does not do that. What does it do? Stay tuned for lecture eight. It does something called table doubling. It is a very simple idea. You can almost get guess it from the title. And if you go to lecture is it eight or nine? Nine, sorry. You will see how this can basically be done in constant time. There is a slight catch, but basically, think of it as a constant time operation. Once we have that, and so this is why you should take this class so you will understand how Python works. This is using an algorithmic concept that was invented, I do not know, decades ago, but is a simple thing that we need to do to solve lots of other problems. So it is cool. There is a lot of features in Python that use algorithms. And that is kind of why I am telling you. All right, so let is do another one. A little easier. What if I want to concatenate two lists? You should know in Python this is a non destructive operation. You basically take a copy of L1 and L2 and concatenate them. Of course, they are arrays. The way to think about this is to re implement it as Python code. This is the same thing as saying, well, L is initially empty. And then for every item x and L1, L. appendx. And a lot of the times in documentation for Python, you see this sort of here is what it means, especially in the fancier features. They give sort of an equivalent simple Python, if you will. This does not use any fancy operations that we have not seen already. So now we know this takes constant time. The append, this append, takes constant time. And so the amount of time here is basically order the length of L1. And the time here is order the length of L2. And so in total, it is order I am going to be careful and say one plus length of L1 plus length of L2. The one plus is just in case these are both zero point It still takes constant time to build an initial list. OK, so there are a bunch of operations that are written in these notes. I am not going to go through all of them because they are tedious. But a lot of you, could just expand out code like this. And it is very easy to analyze. Whereas you just look at plus, you think, oh, plus is constant time. And plus is constant time if this is a word and this is a word. But these are entire data structures. And so it is not constant time. All right. There are more subtle fun ones to think about. Like, if I want to know is x in the list, how does that happen? Any guesses? There is an operator in Python called in x in L. How long do you think this takes? Altogether? Linear, yeah. Linear time. In the worst case, you are going to have to scan through the whole list. Lists are not necessarily sorted. We do not know anything about them. So you have got to just scan through and test for every item. Is x equal to that item? And it is even worse if equal equals costs a lot. So if x is some really complicated thing, you have to take that into account. OK, blah, blah, blah. OK, another fun one. This is like a pop quiz. How long is it take to compute the length of a list? Constant. Yeah, luckily, if you did not know anything, you had have to scan through the list and count the items. But in Python, lists are implemented with a counter built in. It always stores the list at the beginning stores the length of the list at the beginning. So you just look it up. This is instantaneous. It is important, though. That can matter. All right. Let is do some more. What if I want to sort a list? How long does that take? N log n where n is the length of the list. Technically times the time to compare two items, which usually we are just sorting words. And so this is constant time. If you look at Python sorting algorithm, it uses a comparison sort. This is the topic of lectures three and four and seven. But in particular, the very next lecture, we will see how this is done in n log n time. And that is using algorithms. All right, let is go to dictionaries. Python called dicts. And these let you do things. They are a generalization of lists in some sense. Instead of putting just an index here, an integer between zero and the length minus 1, you can put an arbitrary key and store a value, for example. How long does this take? I am not going to ask you because, it is not obvious. In fact, this is one of the most important data structures in all of computer science. It is called a hash table. And it is the topic of lectures eight through ten point So stay tuned for how to do this in constant time, how to be able to store an arbitrary key, get it back out in constant time. This is assuming the key is a single word. Yeah. Does it first check to see whether the key is already in the dictionary? Yeah, it will clobber any existing key. There is also, you know, you can test whether a key is in the dictionary. That also takes constant time. You can delete something from the dictionary. All the usual dealing with a single key in dictionaries, obviously dictionary. update, that involves a lot of keys. That does not take some time. How long does it take? Well, you write out a for loop and count them. But how can you see whether dictionary in constant time? How do you do this in constant time? Come to lecture eight through ten point I should say a slight catch, which is this is constant time with high probability. It is a randomized algorithm. It does not always take constant time. It is always correct. But sometimes, very rarely, it takes a little more than constant time. And I am going to abbreviate this WHP. And we will see more what that means mostly, actually, in six thousand and forty six point But we will see a fair amount in six thousand and six on how this works and how it is possible. It is a big area of research. A lot of people work on hashing. It is very cool and it is super useful. If you write any code these days, you use a dictionary. It is the way to solve problems. I am basically using Python is a platform to advertise the rest of the class you may have noticed. Not every topic we cover in this class is already in Python, but a lot of them are. So we have got table doubling. We have got dictionaries. We have got sorting. Another one is longs, which are long integers in Python through version two. And this is the topic of lecture eleven point And so for fun, if I have two integers x and y, and let is say one of them is this many words long and the other one is this many words long, how long do you think it takes to add them? Guesses? . Plus? Times? Plus is the answer. You can do it in that much time. If you think about the grade school algorithm for adding really big multi digit numbers, it will only take that much time. Multiplication is a little bit harder, though. If you look at the grade school algorithm, it is going to be x times y it is quadratic time not so good. The algorithm that is implemented in Python is x plus y to the log base two of three point By the way, I always write LG to mean log base two point Because it only has two letters, so OK, this is two point Log base two of three is about 1. 6. So while the straightforward algorithm is basically x plus y squared, this one is x plus y to the one point six power, a little better than quadratic. And the Python developers found that was faster than grade school multiplication. And so that is what they implemented. And that is something we will cover in lecture 11, how to do that. It is pretty cool. There are faster algorithms, but this is one that works quite practically. One more. Heap queue, this is in the Python standard library and implements something called the heap, which will be in lecture four. So, coming soon to a classroom near you. All right, enough advertisement. That gives you some idea of the model of computation. There is a whole bunch more in these notes which are online. Go check them out. And some of them, we will cover in recitation tomorrow. I had like to now that we are sort of comfortable for what costs what in Python, I want to do a real example. So last time, we did peak finding. We are going to have another example which is called document distance. So let is do that. Any questions before we go on? All right. So document distance problem is, I give you two documents. I will call them D1 D2. And I want to compute the distance between them. And the first question is, what does that mean? What is this distance function? Let me first tell you some motivations for computing document distance. Let is say you are Google and you are cataloging the entire web. You had like to know when two web pages are basically identical. Because then you store less and because you present it differently to the user. You say, well, there is this page. And there is lots of extra copies. But you just need here is the canonical one. Or you are Wikipedia. And I do not know if you have ever looked at Wikipedia. There is a list of all mirrors of Wikipedia. There is like millions of them. And they find them by hand. But you could do that using document distance. Say, are these basically identical other than like some stuff at the junk at the beginning or the end? Or if you are teaching this class and you want to detect, are two problem sets cheating? Are they identical? We do this a lot. I am not going to tell you what distance function we use. Because that would defeat the point. It is not the one we cover in class. But we use automated tests for whether you are cheating. I have got some more. Web search. Let is say you are Google again. And you want to implement searching. Like, I give you three words. I am searching for introduction to algorithms. You can think of introduction to algorithms as a very short document. And you want to test whether that document is similar to all the other documents on the web. And the one that is most similar, the one that has the small distance, that is maybe what you want to put at the top. That is obviously not what Google does. But it is part of what it does. So that is why you might care. It is partly also just a toy problem. It lets us illustrate a lot of the techniques that we develop in this class. All right, I am going to think of a document as a sequence of words. Just to be a little bit more formal, what do I mean by document? And a word is just going to be a string of alphanumeric characters A through Z and zero through nine. OK, so if I have a document which you also think of as a string and you basically delete all the white space and punctuation all the other junk that is in there. This Everything in between those, those are the words. That is a simple definition of decomposing documents into words. And now we can think of about what I want to know whether D1 and D2 are similar. And I have thought about my document as a collection of words. Maybe they are similar if they share a lot of words in common. So that is the idea. Look at shared words and use that to define document distance. This is obviously only one way to define distance. It will be the way we do it in this class. But there are lots of other possibilities. So I am going to think of a document. It is a sequence of words. But I could also think of it as a vector. So if I have a document D and I have a word W, this D of W is going to be the number of times that word occurs in the document. So, number of recurrences W in the document D. So it is a number. It is an integer. Non negative integer. Could be zero point Could be one. Could be a million. I think of this as a giant vector. A vector is indexed by all words. And for each of them, there is some frequency. Of lot of them are zero. And then some of them have some positive number occurrences. You could think of every document is as being one of these plots in this common axis. There is infinitely many words down here. So it is kind of a big axis. But it is one way to draw the picture. OK, so for example, take two very important documents. Everybody likes cats and dogs. So these are two word documents. And so we can draw them. Because there is only three different words here, we can draw them in three dimensional space. Beyond that, it is a little hard to draw. So we have, let is say, which one is the let is say this one is the makes it easier to draw. So there is going to be just zero here and one. For each of the axes, let is say this is dog and this is cat. OK, so the cat has won the it has one cat and no dog. So it is here. It is a vector pointing out there. The dog you have got basically pointing there. OK, so these are two vectors. So how do I measure how different two vectors are? Any suggestions from vector calculus? Inner product? Inner product? Yeah, that is good suggestion. Any others. OK, we will go with inner product. I like inner product, also known as dot product. Just define that quickly. So we could I am going to call this D prime because it is not what we are going to end up with. We could think of this as the dot product of D1 and D2, also known as the sum over all words of D1 of W times D2 of W. So for example, you take the dot product of these two guys. Those match. So you get one point there, cat and dog multiplied by zero. So you do not get much there. So this is some measure of distance. But it is a measure of, actually, of commonality. So it would be sort of inverse distance, sorry. If you have a high dot product, you have a lot of things in common. Because a lot of these things did not be was not zero times something. It is actually a positive number times some positive number. If you have a lot of shared words, than that looks good. The trouble of this is if I have a long document say, a million words and it is 99 in common with another document that is a million words long, it is still it looks super similar. Actually, I need to do it the other way around. Let is say it is a million words long and half of the words are in common. So not that many, but a fair number. Then I have a score of like 500,000. And then I have two documents which are, say, one hundred words long. And they are identical. Their score is maybe only one hundred point So even though they are identical, it is not quite scale invariant. So it is not quite a perfect measure. Any suggestions for how to fix this? This, I think, is a little trickier. Yeah? Divide by the length of the vectors? Divide by the length of the vectors. I think that is worth a pillow. Have not done any pillows yet. Sorry about that. So, divide by the length of vector. That is good. I am going to call this D double prime. Still not quite the right answer. Or not no, it is pretty good. It is pretty good. So here, the length of the vectors is the number of words that occur in them This is pretty cool. But does anyone recognize this formula? Angle, yeah. It is a lot like the angle between the two vectors. It is just off by an arc cos. This is the cosine of the angle between the two vectors. And I am a geometer. I like geometry. So if you take arc cos of that thing, that is a well established distance metric. This goes back to 75, if you can believe it, back when people early days of document, information retrieval, way before the web, people were still working on this stuff. So it is a natural measure of the angle between the two vectors. If it is 0, they are basically identical. If it is ninety degrees, they are really, really different. And so that gives you a nice way to compute document distance. The question is, how do we actually compute that measure? Now that we have come up with something that is reasonable, how do I actually find this value? I need to compute these vectors the number of recurrences of each word in the document. And I need you compute the dot product. And then I need to divide. That is really easy. So, dot product and I also need to decompose a document to a list of words. So there are three things I need to do. Let me write them down. So a sort of algorithm. There is one, split a document into words. Second is compute word frequencies, how many times each word appears. This is the document vectors. And then the third step is to compute the dot product. Let me tell you a little bit about how each of those is done. Some of these will be covered more in future lectures. I want to give you an overview. There is a lot of ways to do each of these steps. If you look at the next to the lecture notes for this lecture two, there is a bunch of code and a bunch of data examples of documents big corpuses of text. And you can run, I think, there are eight different algorithms for it. And let me give you actually, why do not I cut to the chase a little bit and tell you about the run times of these different implementations of this same algorithms. There are lots of sort of versions of this algorithm. We implement it a whole bunch. Every semester I teach this, I change them a little bit more, add a few more variants. So version one, on a particular pair of documents which is like a megabyte not very much text it takes two hundred and twenty eight point one seconds super slow. Pathetic. Then we do a little bit of algorithmic tweaking. We get down to one hundred and sixty four seconds. Then we get to one hundred and twenty three seconds. Then we get down to seventy one seconds. Then we get down to eighteen point three seconds. And then we get to eleven point five seconds. Then we get to one point eight seconds. Then we get to zero point two seconds. So factor of 1,000. This is just in Python. 210 of a second to process a megabytes. It is all right. It is getting reasonable. This is not so reasonable. Some of these improvements are algorithmic. Some of them are just better coding. So there is improving the constant factors. But if you look at larger and larger texts, this will become even more dramatic. Because a lot of these were improvements from quadratic time algorithms to linear and log n algorithms. And so for a megabyte, yeah, it is a reasonable improvement. But if you look at a gigabyte, it will be a huge improvement. There will be no comparison. In fact, there will be no comparison. Because this one will never finish. So the reason I ran such a small example so I could have patience to wait for this one. But this one you could run on the bigger examples. All right, so where do I want to go from here? Five minutes. I want to tell you about some of those improvements and some of the algorithms here. Let is start with this very simple one. How would you split a document into words in Python? Yeah? . Iterate through the document, the dictionary? Iterate through the that is actually how we do number two. OK, we can talk about that one. Iterate through the words in the document and put it in a dictionary. Let is say, count of word plus equals one point This would work if count is something called a count dictionary if you are super Pythonista. Otherwise, you have to check, is the word in the dictionary? If not, set it to one. If it is there, add one to it. But I think you know what this means. This will count the number of words this will count the frequency of each word in the dictionary. And becomes dictionaries run in constant time with high probability with high probability this will take order well, cheating a little bit. Because words can be really long. And so to reduce a word down to a machine word could take order the length of the word time. To a little more precise, this is going to be the sum of the lengths of the words in the document, which is also known as a length of the document, basically. So this is good. This is linear time with high probability. OK, that is a good algorithm. That is introduced in algorithm four. So we got a significant boost. There are other ways to do this. For example, you could sort the words and then run through the sorted list and count, how many do you get in a row for each one? If it is sorted, you can count I mean, all the identical words are put right next to each other. So it is easy to count them. And that will run almost as fast. That was one of these algorithms. OK, so that is a couple different ways to do that. Let is go back to this first step. How would you split a document into words in the first place? Yeah? Search circulated spaces and then. Run through though the string. And every time you see anything that is not alphanumeric, start a new word. OK, that would run in linear time. That is a good answer. So it is not hard. If you are a fancy Pythonista, you might do it like this. Remember my Reg Exes. This will find all the words in a document. Trouble is, in general, re takes exponential time. So if you think about algorithms, be very careful. Unless you know how re is implemented, this probably will run in linear time. But it is not obvious at all. Do anything fancy with regular expressions. If you do not know what this means, do not worry about it. Do not use it. If you know about it, be very careful in this class when you use re. Because it is not always linear time. But there is an easy algorithm for this, which is just scan through and look for alpha numerics. String them together. It is good. There is a few other algorithms here in the notes. You should check them out. And for fun, look at this code and see how small differences make dramatic difference in performance. Next class will be about sorting. 
</body>
</html>