<html>
<body>
Today we are going to be talking about Data compression. We will begin with what the idea behind file compression is and then we are going to be talking about Huffman Tries which is the way of doing data compression. We are going to see how ABRACADABRA translate into these sequence of 0 is and 1 is. So what is file compression? As you know, if you have a piece of text, it is stored as bits in your computer and what is typically done is that, for each character, you have what is called an ASCII code. So if you were to go into a unique shell and type less than man ASCII greater than, then that will give you the ASCII code for all the various characters. The ASCII code is an eight bit code which means that every character is stored as eight bits. So this is what is called fixed length encoding. why fixed length because for each character, I have the same number of bits but our idea today is to try and reduce the amount of space required to encode a piece of text. If each character I am going to use eight bits then the total number of bits required will be eight times the number of characters in the piece of text. But suppose I do not have to do fixed length coding. You know some character might have two bits associated with them. Some character will be encoded using three bits, some using four and so on, can we exploit this and the fact that some characters occur more frequently than others to design a coding screen which will represent the same piece of text using lesser number of bits using lesser number of bits. You understand the need for doing this kind of compression? Clearly the lesser memory you require, you know if you are transmitting the file, you have to send less number of bits. If you are storing, you will have to store less number of bits and so on. So it is very useful to be able to compress the information that you have. That will bring us to what we call variable length coding. So the number of bits used to represent each character would be different. In particular, character which occur more frequently, we are going to represent them using less number of bits and use that. Characters which appear very infrequently, let is say x or z in the English alphabet, we can have longer sequences. May be more than eight bits. Let is see how this is done. So let is say my piece of text is just four characters java and I decide to encode a. How many characters are there? Suppose my alphabets were just a, j and v. The only things that ever encoded were strings on this alphabet a, j and b. So java is1 example of such a string and suppose I were doing fixed length encoding, how many bits should I associate with each of these? I will need at least two. I ca not do with just1 because there are three different characters and there are only two possible values if I choose1 bit. So I need at least two bits and if I take two bits then how many bits do I need to represents java? two times four is eight. As straight forward as that. But suppose I decide to use 0, just single bit for a and11 for j and ten for v and I will tell you why I am doing this. Then java can be encoded as110100. That would be the encoding and it will take only six bits. It will take the lesser number of bits. Then you can ask me, well, why did I do j as11 and v as10? so the problem with variable length decoding minus variable length encoding is that of decoding. How do you decode? Given a sequence of bits you want to decode it uniquely. So suppose I gave you a sequence of bits, then you should be able to retrieve java from this. Of course I have told what the codes were. You should be able to get back to java. Suppose for instance, I had used this as my encoding, for a I use 0, j is zero one and v is00. So still it should take six bits only and the encoding would be one thousand and zero. From here can I get back to java given this code? Well one could be either a or it could be a j. It has to be a j because we are using this 1. So what would you do with these four 0 is? It could be java, it could be j v v or it could be ja. It is ambiguous. You see the problem? If you have to use variable length encoding, then you could have this problem of ambiguity while decoding. So you have to be careful when you are using variable length codes. This problem would not arise when you have fixed length codes. You understand why because you will take those many bits and then you now determine what exactly the character was. So to prevent ambiguities in decoding, we will ensure that our encoding satisfies what is called the prefix rule which is very simple. It says that no code is a prefix of another code. By code, I mean the bits I use for a particular character. When this was our code, you can see zero was not a prefix of either j or v. j and v were also not prefixes of each other. The encoding arising out of this would be unambiguous and we will see an example to show that to illustrate that. But the encoding arising out of this will be ambiguous because a is the prefix of these and I will show you an example. You must understand what the prefix rule is. So if your codes satisfy the prefix rule, then decoding will be unambiguous. But if it does not, then you will have ambiguity in decoding. So I will come back to the prefix rule in the next slide. Code is the collection of code words. What I have written out here is a code. Each one of these is called a code word. For each character the sequence of bits what is called the code word and the entire thing is called a code. So code which satisfies the prefix rule can be represented as a tree. In particular as a trie. So recall the trie that we have discussed in the last class, the branching was a twenty six way branching. But here branching will only be a two way branching. Each node will have only a two children. Here my alphabets are a b c d r. five characters only. The characters will be stored at the leaves or the external nodes and every for every node the left edge will label with zero and the right edge will be labeled with one. Now a equal ten because you know if you look at this, from root two A, you will encounter ten. When you are coming to R, the code for R will be eleven. Can you see that if I drew such a picture for you, then the code word for any character will not be a prefix of the codeword for some other character. Otherwise it could have ended midway. But it is not because everything is a leaf. Each character corresponds to a leaf. That is the very first statement here. So the code word for one character would not be a prefix of code word for another character. We will represent our codes using such a we trace a from the root to the particular leaf to determine the code word for each character. I need not have shown this picture at all. I could have just drawn this trie and from this you can figure out what is the code word corresponding to this. Now how do we do the decoding? Suppose this is my trie and these are the code words. Now I give you a sequence of bits that is this is my encoded text and I have to decode this text. As you can see, the code satisfies the prefix rule. So how do I do the decoding? So I start from the beginning. You always start from the beginning. You start from the beginning ten. So you will trace out ten. You will get a leaf. You stop and these three characters go away and I get an a. So I have struck off these three and I have written down an a. Now I will take one and the next one is also1. So I get a b and I will strike these two off. I have taken care of these two. Now I get a eleven. Its one point one so zero remains. As you can imagine it will come to the same abracadabra. So that is what this will turn out to be and we can decode it and see. Suppose I give you this trie and I give you this encoded text, how much time does it take to decode? Clearly I am just looking at a bit and I am going to spend one unit of time with every bit. I just look at that bit and go down one level in that trie. so it is basically length which you have to spend clearly. So this is another trie and you know this is a long piece of encoded text and you can figure out what this is. You can take this is an exercise. So what is our aim in doing this? Recall we wanted to build up a code in such a manner such that the total length of the encoding is as small as possible. Suppose this trie was specifying my code and once again I was encoding abracadabra, this has twenty nine bits. How will you compute such a thing? Well let is quickly do that to make sure that you understand. What is the frequency of each character? A 5,B minus 2, C 1,D one and R two. Im using three bits for A, two for B, two for C, two for D and three for R. I am just counting the number of bits. So this becomes 15, 4,2 and six point two nine totally. Now suppose I had another trie say this one, you think this will have less or more? This will have less. A was occurring five times. Here I am using three bits and I am using two bits here. I am saving five bits for a. Of course, I will have to compensate elsewhere. c and d, there are two here and three there. But c and d occur very infrequently. So it is good. This will have less than twenty nine. We are also saving on R. this you can check. It will require twenty four bits. We have to design this in such a manner so that the number of bits required it as little as possible. So let is try and understand. What is it that we are given? We are given the frequency of that character. Suppose I give you a piece of text. You will count the frequency of characters and we are trying to compute the trie so that the length of the encoding we get is as small as possible. Recall that each character is a leaf in our tree. Number of bits used to encode the character is its level number where I am assuming that the root is number zero. So if the ith character has frequency of f i and has level number of l i, then what is it that we are trying to minimize? It is summation fi li. so we have to choose a tree so that this quantity is minimized. Our tree will determine the li is. fi is given to us. We cannot change the fi is. We can pick a tree so that we can get appropriate li is. So summation fi li is called the total external weighted path length of a tree. It should be very easy to see why. External because we are talking about external nodes which are our leaves. What is its path length? The length of the path from the root to the leaf which is basically the number of levels. Weighted because we are multiplying it by the frequency and total because we are summing it up. So we are viewing each leaf as having a weight which is equal to the frequency of the corresponding character. The weights in the weighted are referring to this frequency. From now on, I might call the same thing is weight or frequency. This means the same thing. Here for instance given these weights or frequencies, f1 through fn, we wish to find the tree whose total weighted external path length is minimum. That is what we want to do. We are given the weight on the leaf. We want to build a tree whose leaves will be these and who is weighted external path length will be minimum and will denote this minimum weighted external path length by this quantity. so given n leaves with weights f1, f 2, f 3, fn your problem is to build a binary tree whose leaves will be these n leaves and which will have a minimum total weighted external path length. So we have managed to translate our question of finding the minimum length in encoding such that the length of the encoded message minimum to that of designing an appropriate tree. One thing I am going to assume is that when I write it in this way, f1 is smaller than f2 and these are in increasing order. Now let me show you what the algorithm is. Once again, my text is the same abracadabra. There are five characters and I have put down the frequency of these five characters. I have put red boxes around them. These will have to be the leaves of my tree. Now what I am going to do at the very step is I am going to take the two with the smallest value which are the ones in the ends. These are the two smallest ones. I am going to combine them. How am doing that? I am going to create another node. I am building up a tree now. These are my leaves. I make another node as the parent of these two and this node gets the value of weight of sum of these two. Now these two will disappear from the picture and I will just be left with four nodes and I will repeat the process. So what is the process? Take the two smallest and combine them together into one. Take the two smallest and combine them together into a node and when you combine, you basically sum up their weights. So at the next, we have an option. we can either combine b and r or we can combine r with this one that we have created. Let is see which one I take. I decide b and r to be combined into one. When you have an option we can pick whichever you feel like. So they have combined into one and what we are left is only three node. Now many times I will have to do this process? If I started off with n leaves, how many times will I have to do this process? Every time you are reducing a node by one. so it is n 1 times not n by2. Now which will we combine? Two and four clearly because they are the two smallest ones. So you combine them into one and we get a six. Finally we have only two nodes left five andamp six. They will get combined. This is the picture. We will combine them into one and these are 11. now how do I label? I can just label whichever way I like to. It really does not make a difference. The length of the encoding was determined by the depth of these things. This becomes encoding now and the claim is this is the best. This will give you the same minimum. Whatever was the minimum for abracadabra will be achieved by this. as you can see a which was occurring five times is getting only1 bit. Looks like it is the right thing to do. So this is our final trie. This is my text. This is the corresponding code. As you can see for a you have zero. For b you have 100, the next three characters. For r you have 101, the next three. For c you have three and so on and on. There should be a gap between this one hundred and one and zero because a corresponds to the last one and these are only twenty three bits. These is even better than the previous code which was twenty four and this is the best possible which is what we will argue in this class. Can you do better than this? Let me take the same example and then build another trie. How can I build another trie? We recall that there was an option at each point. Let me take the other side of the option. Let me see what trie I get now. Here there are two minimums. Here there are three 2 is. First I combined these two. Let me do that. I decide to combine r with this one. I get a four. Now which do I have to combine? This four with this two. I combine the four and the two and then I get six. Finally I am going to combine this and this. So this is the final trie I get. It is the same piece of text. Once again a gets only one bit. b gets two. r gets three. a gets one. c gets four now and d also gets four point You think it will be different from 23? It should not be. Otherwise the theorem I am claiming is false. It should be the same. You can count. It will be twenty three because this algorithm is computing the tree with the minimum weighted external path length. Since it is the minimum, it cannot be smaller or larger than the other one because they are both the minimum. So we now need to argue correctness. Why is this computing the minimum? Why does this algorithm compute a tree with the minimum weighted external path length? So there is no reason to believe its too simple to do anything useful. Let us see what the argument for this one is. We will be proving it by using induction on the number of leaves which is same as the number of characters. Suppose I gave you only two leaves, then what is the algorithm going to do? It will just combine them into one and so it will basically give you a tree with the three nodes, one root. this will be zero and this will be one and this will be something and this will be something and clearly it is using one bit for each of the character, you cannot do better. You cannot take zero bits for a character. so it is true when you have only two leaves. So we are going to assume the claim is true when you have n 1 characters or leaves and we are going to show that it is going to be true when you have n characters or leaves. So when we have n characters, what are we doing at the very first step? We are taking the two characters with the smallest frequencies and combining them into one. We are taking the two characters frequencies f1 and f two and we are replacing it with one node of weight f1 plus f two. It is as if you have one character now of frequency f1 plus f2. so once it does that, beyond this point the behavior is as if it was given n 1 characters with frequencies as f1 plus f 2, f3, f 4, f5 upto fn. Beyond that the point it is the same behavior. so beyond the point the algorithm behaves as if it had only n 1 characters with frequencies f1 plus f2, f3 all the way up to fn. using our induction hypothesis it would have computed the best possible tree because these are only n 1 characters now and it would have computed a tree on these n 1 characters with total weighted external path length as this quantity. This was the minimum quantity. This was the notation we used for the minimum. The tree computed by this algorithm has weighted external path length f1 plus f2 plus this quantity. This is what our algorithm has computed. This is the weighted external path length computed by this Huffmen is Algorithm. Now we have to argue that this is the minimum possible. It will not go lesser than this. What we will argue is that the best solutions for f1 through f n equals f1 plus f two plus exactly the quantity that the algorithm had computed. We will argue this now. This quantity that algorithm has computed is actually the best. It is the minimum weighted external path length when your weights are from f1 through fn. How do we argue this? This will follow from the fact that in the optimum tree, by optimum tree I mean that tree whose weighted external path length is minimum. So let is prove this fact. Suppose this factor is true, how does this implies this? Why does this imply? Let is do one step at a time. Suppose had proved this factor that in the best possible tree suppose we had prove that in the best possible tree that two lowest weights are siblings. We will do that in a slightly more formal way. Let is assume that the two minimum are always siblings. Let is argue that if this is true, then it will imply this. We have our best possible tree and the minimum are siblings. Why does it imply that we found the best greater than That is because it implies the best over f1 through f n equals this. This is the best tree. we are going from here to here which means that we have assumed this statement and we are proving that the best tree over f1 through f n has weighted external path length equal to f1 plus f two plus the weighted external path length of the best tree over f1 plus f2 through fn. so now we are kind of trying to mimic what we have already done. let me now look at this tree. Now I am just looking at the remaining tree. This is a tree and let me give this node weight equal to f1 plus f two. Now this is the tree over leaves f1 plus f2, f three up to fn. What will its minimum weighted external path length become? If this is the best tree for the entire thing, for these values or leaves, this should be the best tree. We are looking at the best tree for f1 through fn. I am saying the following. Let is cut off the two leaves and just keep that. Let is give this a name of f1 plus f two point Then this tree is the best tree for these choice of weights also. Suppose there was something smaller possible, then this blue would not have been and best tree for these guys. The best would be a green tree. So suppose the black tree was the best, better than this red one. This tree is the best possible tree when you have leaves with weights f1 plus f 2, f3, f4, f5, f6. This is the best possible tree. So this red weighted external path length is this quantity then and so blue total external path length is red external path length plus f1 plus f two point So which means blue weighted external path length which is this leaf is equal to this leaf which is equal to the best possible. What did we get in our previous algorithm? We got the right hand side exactly. So the algorithm is completing the best possible. If this black is better than the red, then what have I done? I have only increased the black by a quantity equal f1 plus f two while this blue also differs from the red by this quantity f1 plus f two. If this black is better than this red, then this bigger black is also better than the bigger blue which violates our optimal case. But why is this statement true? Why should it be the case that in the optimum tree, the leaves with those two lowest frequencies are siblings? Let is take the leaf with the lowest weight. It will have the maximum level number. Suppose this leaf with the lowest weight comes in between and there is another leaf with a higher weight, this is not optimum. So we have to swap these two. So the total external weighted path length becomes minimum. So the leaf with the smallest weight has to be at the last level. Let is look at its parent and let is look at its siblings which is this leaf. By the same argument this leaf is the second smallest weight because if it for anything else then once again you can swap and reduce. So the leaves with the two smallest weights are actually at the very last level. In all our examples you must have seen that happening. They are all at the last level and they are siblings. You just use this fact, make them siblings and then the problem reduces by one because now you have only n 1 nodes. How do we take care of n 1 nodes? It is the same way we took care of them. Once again you take the two smallest ones, make them siblings and continue. So just this one property being exploited in this algorithm. We got the very simple algorithm to compute the best possible trap. So with that I am going to stop today is class. After we have done priority queues, we are we are going to analyze these particular algorithm to compute its running time. So I am leaving the bit about computing its running time today and I will take it up after we have developed the notion of paradigms. 
</body>
</html>