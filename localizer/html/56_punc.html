<html>
<body>
Today we are going to start with deletion. In the last class we saw how to do insertion, search, computing successor, computing predecessor, computing minimum and maximum in a binary search tree. Today the only one operation that is left is the deletion and so we are going to see how to do deletion in a binary search tree. Then we are going to address the question that I had raised in the last class which was that if I were to insert some n elements into a binary search tree, suppose I were to randomly permute my elements and insert them. Then what can we say about the time that the insertion would take. Today we will see all of that in detail. We are given a node x in the tree and you have to delete the node. We will distinguish three cases. X has no children which will be the easiest case for deletion, x is the leaf in that case. If x has only one child even then the case will be very easy and we will see all of that and when x has two children it is slightly trickier but still fairly straight forward. When x has no children then deletion is trivial. Why is that because the point B is the node x, it does not have any children so it is a leaf. I need to delete the node x. I should just cut this length which means we will have to change either the left child or the right child of this parent. In this case node B was the right child of the parent A, so we have to set the right child of A to null. If B were the left child then we would have set the left child to null. The 2nd diagram in the below slide is the tree that would be left after the deletion. If the node that you are trying to delete is the leaf node then the problem is trivial. What happens if the node that you are trying to delete has only one child? From the slide given below, you are trying to delete A, it has only one child which is B. A does not have a left child. The operation is like that you can think the part ABD as a linked list. It is just like a linked list and you are trying to delete a node from the linked list. You take the previous node which will be D and you will make its left child point to B. Effectively you are removing the two links which is coming from A and you are establishing the link directly from D to B. Are you convinced that this would maintain the search property. Why should B be on the left of D and not on the right of D? Because B is less than D, and B is in the left sub tree of D. We would make B as the left child and everything that is below B that is all the descendants of B are also less than D. Because they are all in the left sub tree of D. We will just continue with them as there is no change. The only change that happens is that the two links from A go away and you set up one link from B to D. So very little has to be done in this case. In the above slide 2nd diagram will be the new setting or this is what will happen after the deletion. You have D, B and F but A goes away. The 3rd case is when the node to be deleted has two children. X is the reference to the node which is to be deleted. The node to be deleted is the one containing D and it has two children. Since it has two children let us do the following, it has a left sub tree and a right sub tree. We find the predecessor of D. We have seen how to do successor but we also said that you can equally find the predecessor. How do you find the predecessor? The predecessor of D would be the largest element in the left subtree. We just have to come left and keep going right, since B does not have right child so B is essentially the predecessor of D in this example. How many children does B have? B can have 1, it can have a left child nothing is preventing us from B having a left child. I could have a situation in which let us say T, you could have something like T. But B does not have a right child, there is nothing in the right side of B. If B had a right child then it would not have been the predecessor of D, because we would have gone down further. B has only one child or no child, the node T need not be there. That is what is being said here B or y is the same thing. The y is the reference and B is the content sometimes I am calling it B, sometimes y but this has atmost one child. We are going to delete B and essentially we are going to move B to D. That is we are not establishing such a link from B to D, but we are going to replace D with B and delete the node B. Why would the search property not get violated by moving the content of B to D? Since B was the successor of D, everything in this left subtree was less than D and B is the largest element in this left subtree. Everything in this left subtree is also less than B, if I move B to D there is no problem as far as the search property is concerned. Everything in the right subtree is more then D and so it is also more than B. By moving B to D again the search property is not violated. I can move B to D and can I delete B easily. Because B has either no child or one child. We have already seen how to delete a node which has no child or only one child. If B had a left subtree and suppose I decide to move B to D and there is nothing left so we will delete the node B. When we delete the node B, what happens we will make the right child of A point to that node. The node B gets deleted and the link corresponding to that goes away and we create one link and it goes to the point where it is directed and B moves up. That is the operation and now we have covered all the three cases. The 1st case was when there were no children, 2nd case was one child and 3rd case was two children. We said in the 3rd case we will have to move the content of B to D and then delete the node B. We worked with the predecessor but we could also have worked with the successor, since D has two children we can also find the successor of this node by going once right and then keep going left. The same kind of a thing can be done even there, we could have replaced D with its successor instead of its predecessor. But in this example I have shown the predecessor. What do you think is the running time of the delete operation? Suppose you do not even have to search for the node. I tell you this is the node and I give you the reference to the node that you want to delete. How much time does it takes to delete? In the 1st case when the node is a leaf, how much time it would take? Order one because it just needs to go the parent. There is a pointer in the node, reference to the parent node I just go to the parent and I just update the link that is the right or the left child of the parent. I am giving the reference of the particular node which has to be deleted. In every node we also have a parent, left child and a right child. We can always go back to the parent and update the content to show the deletion operation. In the 2nd case if we are deleting the node A, then once again we need go to the parent and modify its left child, again a constant time operation. In which case do we take more time? In the case 3, because here we have to find a predecessor or a successor. Predecessor can take time as large as the height of the tree because we will have to go once left and then keep going right. We can take in the worst case time proportional to the height of the tree. Case three takes more time and the time taken in the worst case is the order of the height of the tree. The pseudo code for deletion is given in the below slide, so that you will understand roughly what is happening and we do not have to look in detail. If the left or the right is nil then we know that either it is a leaf node or it is a node with only one child. Then in that case, z was the node which I am trying to delete. So y ? z and we look at the TreeSuccessor z. I am not completely sure that what I have is right, so let us just skip this. You would have understood the delete operation. I might have made some mistakes somewhere in the pseudocode. Predecessor or successor is the same thing, we can also work with the successor that is what I said. For the successor we have to search in the right tree. I do not think that it is very critical but let us skip this thing for now. You understood the delete operation and the pseudo code you can all write yourself. Suppose I give you a binary search tree and I do an in order traversal of this binary search tree. What does in order do? First the left then the 5th node then the right. First we will be printing out all the keys on the left. Suppose all I do when I visit a node is print out the key. That is what my traversal procedure is, first I will print out the keys which are on the left in some order. Then I will print the key which is in the center and then I will print out the keys on the right. This means that I will print out the root key five after I have print out the left and before I print out the right. All the keys on the left are less than or equal to five and all of the keys on the right are greater than or equal to 5, which means that five really comes at the right place in the ordering of these keys. Because everything which is less than five comes before five and everything that is more than five comes after five. Hence five come really at the right place and the same argument can be set for every key not just the root key. When will you print three out? After I have printed everything to the left which means everything that is smaller than three will come before three and then I will print out things on the right. In in order traversal, if you were to just to look at this and see in what order you would print out. First you will come to three and then go left, then come to two and print this one. Then you will print 3, five then you will come right and then go left and so on. This is the order in which you will print the keys. The property of the in order traversal of a binary search tree is that it prints out the keys in increasing order. This can be a good method of sorting a bunch of keys. I will call this the binary search tree base sorting procedure. What is the method? You have a bunch of keys which you want to sort. You first insert all the keys into a binary search tree. That is what you are doing in the slide given below. You are taking all the keys and inserting them into a binary search tree and then just do in order traversal of this tree. You will get all the keys in an increasing order that is you have sorted a set of keys. How much time does this procedure take? We have to insert all the keys and then we have to do an in order tree work. Let us first look at how much time does the in order tree work take. How much time does it take to traverse the nodes of a tree in in order? It is order n. Why it is order n? We have to print all the node but I might take much more time. I need atleast order n time may be I need more time. We will look at this question later. How much time does it take to do an in order tree work? Actually it just takes linear time that is it takes order n time. We will not do it in todays class, we will see how to argue that it just takes order n times. How much does the part which is given below takes, when I am inserting all the elements into a tree? for I? one to n TreeInsert T, Ai It is n log n. But why it is n log n? This is my BST sorting procedure. I want to sort the keys given in the above slide, I insert them into a binary search tree one after the other. First five then 10, seven then when I insert one it will go as the left child of five then when I insert three it will go as the right child of one. When I insert the other one it will go as the left child of three. It depends upon how you are doing it, it could also have come as the left child of the other one and it is the same thing. And eight would come as the right child of seven and the final diagram in the above slide is the tree you would get. If you have to do any in order tree work on this tree you would get exactly the sorted sequence. How much time does it takes to insert all the n elements? It depends upon the sequence. If I were to sort let us say given a set of numbers one through n and I just want to sort them. The total time taken to insert this numbers is equal to the sum of the levels at which the nodes will come up because when I insert a particular number I come down the tree and I insert it at a particular place. The number of levels I traverse or the number of comparisons I do before I insert it is exactly equal to its level. Either level or level plus one or level minus one but you can think of it as the level for now. If I had inserted the numbers in sorted order, first I inserted one then I inserted 2, three and so on. What is the kind of a tree I would get? I would have one followed by two followed by three and so you remember that kind of a picture. I would get a tree some thing like the one which is given in the slide in blue color from one to n. What is the sum of levels? It is from 0 plus 1 plus 2 plus 3 n 1 and O is the series which sums to. That is not good, the time taken for insertion could be as bad as. Is this clear to everyone and this bring backs the question that we had asked in the last class. I take a random permutation of the elements. There are n factorial different permutations I take one of them at random. I insert the elements in this particular order. I want to compute the time it takes to insert. The time required for insertion is a random variable. We saw an example where the time required for insertion could be as bad as. That is what I showed you in the previous slide. In the best case it could be quite small and we will the best case. It is really a random variable it depends upon the sequence and the permutation in which we are inserting the elements. In fact we had discussed the best case in the previous class, we said the first element inserted should be then it should be and then and so on. All the way we had not computed the total time for insertion. The total time for inserting these n elements is really a random variable and for random variables we compute what is the expectation of the random variable. Recall what is the expectation of a random variable? If a random variable takes many different values then the expectation of the random variable is obtained by taking the average if the probability of each value is the same. Otherwise you essentially do many trials which means that you compute the value of the random variable then you do the experiments once again and so on. Look at the value of the random variable that you get and take the average over all the trials. That is how you compute the expectation of the random variable. In our case it is easier because each of the permutation is equally likely. We are saying we will just pick one of the permutations uniformly at random. Each of the permutation is equally likely so we are going to see how much time it takes to insert the elements in the order given by a certain permutations. How do we compute the average? We will take a permutation, insert the elements in that order and compute the time it takes to do that insertion. Then take another permutation compute the time it takes to insert the elements in that order, take the 3rd permutation compute the time it takes to insert the elements in that order and so on. There are n different permutations, while compute the time it takes to insert the elements in the order specified by these n different permutations. You will get the total time this huge quantity and will then divide by n to compute the average and that could be the expected time it takes. Just to summarize, for each of this n permutations we will compute the time taken to insert the keys in the order specified by that permutation and then we will compute the average. The average is computed over the n permutations. We will denote this quantity by T n, whatever is this value will be T n. Let us see how to compute T 3. T 3 is the tree obtained or is the expected height of a tree on three nodes. What are the various possible trees on three nodes that we get? What are the various permutations of elements 1, 2, 3? We will have six different permutations as given in the slide. When we have this particular permutation what is the tree we would get? If we were to insert the elements in this order 1 two 3 and you will get a tree whose root is 1, two would come to the right and three would come after that. When the elements are inserted in this particular order 1 three 2, we would get a tree 1, three to the right and two to the left of three point If the elements are inserted in this order 2 one 3, we will get a tree which is 2, one to the left and three to the right. When elements are inserted in this order 2 three 1, we get a tree which is 2, three to the right and 1to the left. When elements are inserted in this order 3 one 2, we get a tree which is 3, one to the left and two to the right of one but to the left of three and in this order 3 two 1, we get 3, two to the left and one to the left. What is the total time taken for insertion? We recall what we said, it is just the sum of the levels of the nodes. The levels of the nodes are 0, 1, two and so the sum is three point In the next one the levels of the nodes are again 0, 1, two so the sum is three. For the next one it is zero and one in which both one and two are at level 1, so the sum two. For the next one also the sum is two. For the 5th and 6th one the sum is 0, 1, two that is three. Total of sixteen and so the average is which is two point six six which is T 3. Hence we computed T 3 as 2. 66. That is what being said here, for each of the n permutations we are going to compute the time taken to insert the keys which is what we did for T 3. Then compute the average that gives us the value of T 3. But we cannot do the computations in this manner, we have to do it cleverly because we have to compute what T n is. Now am going to fix a particular element i and I am going to look at all permutations in which the element i is the very first element in the permutation. There are n 1 permutations in which i is the first element. In these n 1 permutations the tree that we obtain will have i as the root because it is the very first element and then the keys one through i 1 will be in the left subtree of the root and the keys i plus 1 through n would be in the right subtree of the root. Let us look at one of this n 1 permutations and restrict our attention to the keys one through i 1. They will be coming at many different places and at some places in this permutation. Let me look at another one of these n permutations. These keys one through i 1 would be coming at some other place. If I look at all of these n 1 permutations they will induce permutations of keys one through i 1 elements also. Every permutation of one through i 1 would be there. In particular each permutation of one through i 1 would occur how many times. There are n 1 permutations in all and there are i 1 permutations of the elements one through i 1 and there is no reason why one of these permutation will occur more often than the other permutation. Each of them is occurring equally likely. How many times is each one of them occurring? It is times. You can also think of it in a slightly different manner. You have these i 1 elements somewhere and the other n i elements are getting inserted at different places. How many different permutations are there of those n i elements that are getting inserted? You can compute that and it will be exactly this quantity. This is a simpler argument, there are n 1 permutations in all and there are i 1 permutations of these elements one through i 1 and there is no reason why one of these permutation should be more likely than the other one. They will all occur the same number of times. It is symmetric of law, each permutation therefore of these elements is occurring exactly times. Suppose I had only i 1 keys, one through i 1. Then the average time taken to insert these keys is T i 1, this is what we defined T n. This average is the average taken over all the permutations of one through i 1. The time taken to insert all these i 1 permutations are just i 1 T i 1. The average time is T i 1 and the average is taken by computing the total time to insert all the i 1 permutations divided by i 1 The total time to insert all the i 1 permutations are i 1 T i 1. For instance in the example that we did earlier for T 3, the total time taken to insert all the permutations was sixteen which we had computed, that was the average times six point When we are inserting the keys one through i 1 into the left sub tree, we go back to the previous setting. Recall we are considering only permutations in which the first element is i. The keys one through i 1 when we are inserting they will all be compared first against i and then we will go and put them in the left subtree. Each key has to be compared with the root which is i. It is like as if I am creating a left subtree of i 1 elements but I can not just count that as the average call. I am also counting one more because for each of those elements in the left subtree their level is actually one more than, if it were just the left subtree. Let me clarify what I am saying. In the above slide the small round in blue color is the i and the keys one through i 1 are coming inside the triangle. If that triangle in blue color were my tree then I know that the average time to create this tree is T i 1 but I am creating a tree of over n nodes. The keys one through i 1 are coming in the first triangle and the other keys are coming in the next triangle. How much time I am spending in creating this part darker triangle? It is the average for one through i 1 plus one more for each one of these, because first I compare with i and then come down because the level of each of these is actually one more in tree i than it is in the tree i 1. Then it has level two in the i 1 tree and level three in the original tree. What is the total time to insert all the i 1 Permutations? Recall T i 1 is the average time to insert i 1 keys. In the tree that I am creating am taking one unit extra for every node that I am inserting, because first I am comparing it against the node. i 1 T i 1 plus i 1 is the time I am taking to insert T i 1 keys and that is the average time I am taking to insert the i 1 keys in my tree. What is the total time? I have my i 1 different permutations so the total time is this product i 1 T i 1 plus i 1. Each of the permutations appears so many times that is times. What is the total time I spend in inserting keys one through i 1? The total time to insert all the i 1 permutations is i 1 T i 1 plus i 1. But each of the permutations is appearing times. So it is just times i 1 T i 1 plus i 1 which is n 1 T i 1 plus i 1. This n 1 T i 1 plus i 1 is the total time I take to insert the keys one through i 1 into my tree where this sum is taken over all the n 1 permutations and this is not actually the total time but this is the total time for permutations in which the first element is i. The time to insert keys one through i 1 is n 1 T i 1 plus i 1. Similarly the time to insert keys i plus 1 through n will be similar to the one before. Wherever there is i 1 I will replace it by n i, because that is the number of keys I am inserting. That would give me this expression n 1 T n i plus n i and this is to insert the keys in the right subtree. The total time to insert all the n keys is just the sum of the above two quantities. n 1 T i 1 plus T n i plus n 1 is the total time over all the permutations in which the first key is i. What is the total time to insert all the n keys in all the n different permutations? It is just the sum of this quantity n 1 T i 1 plus T n i plus n 1 as i goes from one through n because the first key can be one or two or three point n 1 All I am doing is trying to figure out the total time taken to insert all the n elements not in one permutations but over all n permutations put together. I am trying to do it in a way so that am able to analyze it. There are i 1 different permutations of i 1 elements. In the sequence of 1through n those i 1 elements are present at different places. All possible permutations of i 1 different permutations of those i 1 elements are there but each of those permutations itself is occurring n 1 over i 1 times. We have to keep that in mind. We are going to work with the expression which is given below. n 1 The total time to insert all the n keys is above thing, this is exactly the sixteen which we had computed for T 3. What is the average time to insert n keys? It is basically, this is n 1 the total time, so this divided by n would be the average. Below given is the one which I would get. Just to make sure this divided by n will give me and this expression I have written where i go from one through n. Note that each of these terms T i 1 and T n 1 will appear twice. If I look at T 3, it will appear once for i equals four and it will appear once for i equals n 3. Each of the term will appear twice, so that this part of the sum is two times T i where I going from zero through n 1. This part of n 1 have moved out, so it is n 1 where I go from zero to n divided by n, so it becomes just n 1. This n 1 is not multiplied by and this only multiplies the following part. Why do i go from zero through n 1? Because you will never generate T n neither from T i 1 nor from T n i. You will generate T 0, when i equals one you will have T 0 and when i equals n you will again have T 0. What is T 0? T 0 is zero, in fact T 1 is also zero. T 2 is not zero but T 1 is zero because it is just a single element. We say it is at level zero so we just do not count it any time for inserting it. Such a thing is called recurrence relation. The function T is a function of n, we are expressing the value of this function at point n in terms of its values at previous points. I can use the below given relation to compute T 0, T 1, T 2 and so on. T 0 is zero. What is T 1? When we substitute n equal 1 in the above equation, we get T 1 as zero which we argued it before. So T 0 and T 1 both are zero. I can use that to compute T 2. What will I get the value of T 2? If I were to just use this expression I would get one which is explained in the slide given below. Thus T 2 turns out to be one. If you are not convinced so far lets also compute T 3. T 3 will be times T 0 which is zero so let me ignore that. T 1 which is also zero so let me ignore that and T 2 which is non zero so let me leave that around plus n equals 3 1. T 2 was one so this becomes plus two which is two point six six that is exactly what we computed. You can use this recurrence to compute any T I. We have done something fairly sophisticated. We have obtained some kind of a relation which tells us any T n provided we know the previous values. But we will do a little bit more, we will try to figure out how to solve this recurrence relation also. That is what we are going to do now. The T n is times the sum of the previous T plus n 1. I can write T n 1 is times the sum of the previous T plus n 2. I just replace the n by n 1 and so I can just rearrange this quantity or times this sum equals, I have moved this n 2 on the other side so I get T n 1 n plus 2 and I have scaled it by because I am trying to compute instead of. equal T n 1 n plus 2 If the above equation were times, this would just have been this part T n 1 n plus 2, if you cancel out the n the is exactly this part T n 1 n plus 2. I just want to compute this quantity, because now am going to substitute this in the previous expression that is. I have computed zero through n 2 as this quantity, so am going to substitute that. Thus T n then becomes this sum plus T n 1 plus n 1. Then I just did some rearrangement, that is and that makes it. The cancels out and so I am just left with two times. So we will work with the below equation. All I have done is some rearrangement to simplify things. I have written T n in terms of T n 1. T n was in terms of all the previous T. This is the simplification I have achieved with this point. Let us see. It is a bit of a dense slide but we will run through this very quickly. This is what we have. I will just replace that is is less than two because n 1 is less than n. That is why the less than or equal to, actually it should be strictly less because is strictly less than 1. I just simplify this a bit and now I am going to do the following. I am going to replace T n 1 by using this recurrence relation that is by using this expression. The which is times T n 2 plus 2, where the other plus two is coming from the before expression. All I have done is replacing T n 1 with. Let me just simplify it. The n and n cancels in that expression so I get and two is the same then. This is just the simplification and it is exactly equal. Once again I am going to do the same. I am replacing T n 2 with the value of that. What is T n 2? It would be T n 2, that is what I am going to replace it for T n 2. When I do that n 1 gets cancelled and I get T n 3. This multiplies with this two and gives. This part is the same as. When I replace it I get this and this quantity gets decreasing with every step and the sum inside keeps increasing with every step. Next time I will add, the next time I will add and so on. Eventually it goes down and when T n 4 goes down to n n, I get a zero. And in the denominator I would get n n 1 so it is one and I just get n plus 1. Inside I will get all the terms going up to plus two. Since T 0 is zero that part goes away and I get exactly the equation which is given below. So I get T n is less than or equal to the above sum. This is the sum of a harmonic series and it is going up all the way up to. We are summing a harmonic series, we have to sum. One trick that we employ very often, you take this graph and this is a graph of a function. These are the points 1, 2, 3, four and let me draw line at two. What is the height of this rectangle? It is, the width of this rectangle is one and its area is. I have drawn a line at 3, so its area is. I am getting the terms so next one is, and the last one at n, I will draw it in this manner. This sum is less than or equal to the area under the curve f x equal and it is atmost the area under the curve in between the limits one through n. Recall T n, it is that is harmonic sum plus two. I am going to just put that two n plus 1 and that harmonic sum was the integral of from the limits one through n plus two. This integral part is just log x. It will be just log of n and two n plus 1 ln n plus two is exactly the sum which is O n log n. T n O n log n It is the expected time for inserting the n keys. We have done a very sophisticated computation. We looked at all the n different permutations possible and also we computed the total time taken to insert all the n different permutations and we took the average. We got n log n. Recall we saw the worst case was and there is a particular permutation which puts the elements in increasing order for that the total time for insertion is. But the average time is n log n. The best time is also n log n and the best time would happen when the tree was very shallow. If you have a tree on n nodes and it has a height atleast log n, log n 1 or roughly. If you take a complete binary tree of height log n the last level has keys that is in the leaf there are leaves. How much time you will take to insert each one of those leaves? Log n, because you will have to come down the entire tree. So to insert each one of those keys you are taking time. Just to insert the leaves you take time which is n time a function which is growing faster than n . It is some constant time but it is n. In the best case you are taking n log n time, in the worst case you are taking time but the average case is also n log n. That is a very interesting part. If I would ask you the average case, you would just take the average of the above two cases and report it. Why it is turning out to be O n logn? What does it convey? Most of the trees are fairly shallow and do not have too much depth. Most of the trees have depth of only about log n or some constant times n log n. So that the average is still only n log n. You have a bunch of numbers, the numbers here are the total time for insertion under the various permutations. The smallest of those numbers is n log n, the largest of those numbers is but the average is also n logn or some constant times n log n. That means most of the numbers are closer to the minimum than to the maximum. That is all I was going to discuss in the class today. What we discussed today was the deletion procedure and then we also discussed this particular analysis which says that if you were to take a random permutation of n elements and insert them, then the average time or the expected time for insertion is n log n. In the worst case there could be a permutation for which the time taken is. We have seen examples of those, if the elements are in increasing order or in decreasing order then we take time. The best possible permutations are also going to take at least n log n times or some constant times n log n. But the average case is also n log n. 
</body>
</html>