<html>
<body>
The things we can talk about today, we can talk about this code. We can talk a little bit more about the hash functions. And we can talk a little bit more about amortization. What to do guys want to hear? Amoritizaiton. OK, so one vote for amortization. So who wants to look at the PSET code? Who wants to talk about hashes? Who wants to talk about amortization? Two, three, four, five, OK. So then let is try this. Let is look at the PSET code then talk about amortization a bit at the end. I do have to talk a little bit about hashes though, because I owe someone a question from last time. And the question was, we have rolling hashes, so the hashes look like this. K where K is a big number, modulo p. And we argue that it is really nice if p is a prime. And then the question was, what if instead p is two to the w, and is not prime, as long as the base that we are using is co prime with p? Does this work? And the answer is I did not want to say yes without making sure that I do not say something stupid but the answer is yes, this works just fine, because the way a compute multiplicative inverse is is you use so something called the extended Euclid is method. And if we have b and p, then if we compute their GCD, the that is the greatest common divisor so GCD is greatest If you use extended Euclid you get something like xb plus yp equals GCD of b and p. So if this is 1, then you have xb plus yp equals one point And if you are working modulo p, whatever that is, then you have that xb is one mod p. So there is your multiplicative inverse. Well so now that is nice math, right? But that does not tell me why are we not using this. So with the multiplicative inverse would work, but there is something else that is wrong with using two to the w. Will this give me a good hash function? OK, the fact that it is p might be confusing. So let is say h equals K mod two to the w. And remember that the K is some digits in base b, right? It is a big number made out of digits in base b. So K is d1, d2, d3, all the way up until d length in base b. And I will make things easier and say that b is two to the 8, because we are working with ASCII characters, or colors, or something that fits nicely in a bit. So what could go wrong with using this? Well if your series of if your K is bigger than two if it is K is bigger than two to the w It will be, for sure. Yes, that is the problem, because then you will loop. You will get the same hashes for Yeah, yeah. So you will get So hashing takes a lot of possible inputs and maps them to a relatively small set of outputs. Inputs hash output. And we argued last time that we are going to have collisions no matter what, because we have a ton of inputs and not that many outputs. For example, if we are hashing strings that are a million characters then this is going to be two to the eight to the one million possible strings. And then the number of possible values is, if we are using the word size, two to the thirty two point There is no way we can design a function that will take this many inputs, map them to this many outputs, and not do collisions. But instead, what do we want? What makes a good hash function? Say my hash function is zero for all the K is. Is that a good hash function? It is an excellent hash function. What is wrong with it? You would put everything in one so that it is searching, or it would take a long time? Yeah, searching takes a long time. And we have do not do sorting with this yet. Searching takes a long time, string sub matching will take a long time, it is horrible. So what would that distribute like over all All right, so we want something that looks sort of random. The ideals hash function takes an input then gives it a random output, and then stays consistent. So when it sees an input, returns the same output. So I think distribute is the keyword here. What is wrong with this hash function? If it takes random data, it is going to distribute it randomly. That is true, so that is all good. But what data that we might see in real life will make it behave badly? The K is a series of characters, right? Maybe. It just could be anything. But we know for sure that L will be larger than w. Say L is a million. OK, well that sucks. Oh, no. That in itself, that does not suck. That is what let is us do sub string matching really fast, even if we have large strings. say for two to the w, though, because then it will be much larger, like the number of Yeah, but that is OK. So I am OK with doing this as long as all the values here are distributed sort of uniformly here. So that is fine. OK. But there is I am arguing that there are some values which will make this hash function behave badly. And that those values are so simple that we might see them in real life. OK, what if all these numbers are what if all the digits are even? So d is zero mod two point What happens to K? Well, you are saying that instead of two to the w, we are just using two point So no, the modulo is two to the w. Say it is two to the thirty two point So d are the digits that make up my K. So what if the base is two to the 8? So I have digits from zero to 255, two hundred and fifty six of them. And all the digits are zero modulo two point For my sub string matching example, what if all the characters in the sub string are even?  Not the same thing. But there is a problem. They will hash to so if all the digits are zero modulo two then what about the K? zero modulo two Yep. So it is just like when you have numbers in base ten point ten happens to be divisible by two point So if your last digit is even, then the entire number is even. That makes sense, right? That is math. Please nod, tell me that I am making sense. OK, so here, the base is two hundred and fifty six point And it is also divisible by two point So if your last digit is divisible by 2, then the whole number is divisible by two point So then if I take this K modulo two to the thirty two then the hash is also going to be divisible by two point Why does it matter if the hash is divisible by 2? So it matters because this is supposed to be my universe, right? These are supposed to be all the outputs. And I am saying that if my inputs look like this, then the hash function will not distribute them uniformly. Instead, if this is my possible set of outputs, the hash function will always put outputs in this half. So the outputs will always be here. And these are the numbers that are divisible by two point So these are even, and these are odd. And this area gets no love. Absolutely no number will hash here. So Wait, what about something with all odds? Something with all odd digits? Because you are asking You have all A is rather than all B is in your sub string or in your string. Or because your last digit was odd. If all of our digits are odd then the last digit is odd. And then you had also get something odd, right? Yeah. So there is a pattern. But there is an even distribution. Well if your hash function is always odd, then it is not an even distribution. It is Wait, our hash function? I thought we were talking about Is not it even if your K is even? And if it is odd? Yeah, so that is bad. Because if all your K is happens to be even say if you are doing the nucleotides, and the nucleotides are A, C, G, T. If they happen to be encoded as, say, 0, 2, 4, 6, then these are all even. So the hash function will always be even and I am wasting the last bit. So if I am building a hash table, half the entries will be wasted. They will never get anything in there. I am just wasting memory. So if you could guarantee that your inputs would be evenly distributed So if our inputs are random then the hash function most hash functions will do a good job of producing a random output. The problem is real life inputs are not random. For example, if you get asides from this if you get data from a camera, so if you get your color pixels from a camera, then because of noise those might have the last few bits, always be the same thing. Also it seems like in real life, in his book, argues about this. It seems like in real life there are a lot of sequences that look like that, that would make your hash function behave poorly. So again, the keyword is distribute. If some non random property in the input is reflected in the output, then that is a bad hash function. Would you gain a lot of time from your mod operation? Because in mod two to the n you just truncate any bits to the left of the n. Yeah, so that is why we would do this, right? That is why we are even considering this case. Because that had be really nice to be able to not So modulo is faster, but in return my hash function is crap here. So usually we prefer it turns out that in practice nicer hash functions give better speed improvements overall. So if you think of how a hash is laid out in memory, you will see that because of caching. And everything gets better to take more time on the mod function and use up all your memory for the hash table. So this is why we do not use the and we use this. Not because of this argument. So a good question required a lot of talking and remembering what is a good hash function, what is a bad hash function. Thank you. OK, let is look at the code a little bit. Everyone looked at it, right? So this time we have modules. We do not have everything in one big file. Can someone tell me what are the modules we care about, and why? The problem with the one is we have to code ourselves. OK, let is start with that. Sub sequence hashes interval sub sequence hashes. OK, so these are all in DNA seq, right? So the module is so yeah, the PSET hopefully says that you need to upload this file because it is the only file you will need to modify. So everything that we need to write is here. Now pretty much everything that is in that file needs to be modified. So I am not going to list them out. What else do we want to read in that PSET? Rolling OK, where is rolling hash? In the So what is different between the API in rolling hash and the API that we talked about last time? Yes? Them having the pop, or it would skip. And that is something else just has a slide, it puts everything in one operation. All right, so we have append and skip. And we built some beautiful code with that. And we looked at some fancy math because of it. But it turns out that for this PSET we can get away with slide. And we started from slide and built these two methods last time. So I am not going to explain slide again. It is exactly what we had in the code before we started breaking them up. OK so this is the rolling hash. It is good. Do we care about anything else? I guess you can look at the rest of the code, if you feel like it. You can look at the rest of the code if you feel like it, yep. So I highlighted one file that might be useful, and that is Kfasta. py. That file has a FASTA sequence class, and that is reads from a file and returns something. And the important thing is it does not return a list. If you remember the doc dists, doc dist one thorugh doc dist eight dot PI, fun times. What we had there was we took the input file, and we read it all a list. This time we are not doing that. We are writing, what, twenty lines of code instead of what could be five lines of code to read the input. Why is that? Less memory? Less memory, OK. So if we are doing it this way, chances are that if we tried to shove the whole input into memory, it would not fit. And it would crash and you would get zero on the test because of that. So that is not good. So what do we use instead? Does anyone know what this thing is called? What this class is called?  Iterator, very good. Why do they call it FASTA? Because it goes faster? I think the letters are a bio acronym. Oh, OK. Does anyone, does anyone do bio here? I have seen that before. So it is a bio thing. Let is not worry about it. OK. Or, your can use that for any type of file. Like, you do not have to use it just for bio files. Well, presumably it is reads, it takes advantage of the format that they are stored in, and gives you a list instead of something else. So how does an iterator work? Suppose you are building your own iterator. What do you have to implement? Iterator OK, let is start with next, that is the fun one. What does next do? It is like pop. OK, so it is like pop in what way? It gives you the next character. OK. And what happens when you are at the end of the list? It stops. How do you stop? It raises an exception? So next will either return an element, that is the next element in the sequence that you are iterating over. Or it will raise a stop iteration exception error to stop iteration, cool. So what is the other method? Someone said it before, say it again. Iter. Iter. What does this do in an iterator? It returns itself. All right, very good. In an iterator this is how you will implement it all the time. Does anyone know what is the point of iter? So you can return an iterator? Because that is what it told us to do in the PSET. OK, so iter returns and iterator. But it does not you do not have to start from an iterator. You can start from any object. And if it has a method iter, then it should give you an iterator that iterates over that object. So if you have something like a list 1, 2, 3, four then if you call iter on this, you will get an iterator for it, hopefully, right? And this is what Python uses when you say for i in. So behind the scenes, whatever object you give it here, gets an iter call. And then that produces an iterator. And then Python calls next until stop iteration happens. So you can write an iterator that almost behaves like a list. You can use it in these instructions, and it works as if it was a list, except it uses a lot less memory, because it computes the elements. Hopefully every time next is called, you are computing the next element that you are returning. If you are storing everything in a list then returning the elements that way, that is not the very smart iterator. OK let is look at the last page. So the last page has an iterator on top. And the iterator computes given a list, it computes the reverse of that list. And you can see that it does not reverse the list and then keep the reversed list in memory. Instead, every time you call next, it does some magic with the indexes I think the magic is called math and then it return something for as long as it can. So this is how you implement reverse without producing a new list. If the original list was order, say had n elements, then if you had produce a new list, you had consume order and memory. This think consumes order one memory, and the running time is the same, asymptotically. OK, any question on iterators? So it is going from the very end, oh, to the very beginning, and then it is stepping back. So reverse, if I give it the list 1, 2, 3, 4, I want reverse to give it back 4, 3, 2, one point Except it is not going to return a list, it is going to return something that I can use here. Mm hm, ah, OK. OK, yes. Is it ever possible to, sort of, rewind the iterator to like, sort of, reset it? OK, is it? No. Nope. So Python iterators are simple. All you can do is go forward. OK. The reason that is good is because you can use them for streams. So if you get data from a file, or if you can get data from the network, you can wrap it in an iterator. If you wanted to support resume on data that you get from the network, you had have to buffer all the data. So you would have to call the iter about that again and Yeah. Yeah, if you want to rewind, get another iterator. OK, that is a good question, thank you. So these are iterators. Now we are going to go over some Python magic, which is called generators. So look at the iterator code, and then look at the equivalent code right below it. So twelve lines of Python turned into three lines of Python that do exactly the same thing. So the reverse method will return an object that is an iterator, and that you can use just like the iterator in the reverse class. Do people understand what that code does? If you do I am so out of here, we are done. What does yield do? What does yield do? All right, that is the hard question, what does yield do? I will probably spend the rest of the session on the answer to that question. You are asking all the had questions today, man. So yield, does anyone know conceptually what yield does? Not in detail, just what is it supposed to do so that the rest of the code works? Yes. If you are driving someplace and there is a yield sign, you pause. OK, Python yield. So I like the word pause in there. The word pause is useful. So say, instead of implementing this, say we are implementing sub sequence hashes. It kind of spit something out, but keeps going. Yep. Returns OK, so suppose you are implementing sub sequence hashes. What is the worst, worst possible way you could implement this? Return a list. OK, so the worst, worst way is to go all the way, brute force, do not use the rolling hashes, do not use anything. The next best way is to make a list, right? So you are going to start with an empty list. Then you are going to use the rolling hash in some way. And in some loop you are going to say list. append e. And then you are going to return the list. Does this makes sense? OK, what is the problem with this code? You are going to have a huge list. Going to have a huge list. So the way we fix it with iterators is we remove this, we replace this with yield e, and we remove this. And now it is a generator. And now this consumes a constant amount of memory, instead of building a list. And as long as you only want an iterator out of this method, you will get the right thing. Your code will still work in exactly the same way. OK, so the big question is what does this guy do, right? This is where the magic is. So I already said, as a first hint, that this guy will return an iterator. So can someone try to imagine their Python, and see this? So suppose it is your Python, you see this. What do you do? You wait for some sort of command of some sort, right? No, let is try something else. OK. So the execution of this pauses. What happens? So we are looping somewhere, we got a yield. We stop, what is the first thing we do? Spit out e. So you are saying you return e from this guy? out e So I want to return something I want to return something else from this. So I want to use this as if it was a list, yes? We store e somewhere. OK, store e somewhere. Do you return the pointer of e? Almost, so there is a word for the object that I am returning. So I want to use it as if it was a list. So I want to pretend that I had returned list in this method, right? So what is the closest thing to a list that I can return. An iterator. An iterator, thank you, all right. So we will grab some information from here. We will put it in a nice box. And that box will behave like an iterator. OK, so the first thing, someone said put e away, so that is when we call next we are going to spit that out. What else do I need to put away?  Yep, so this is a lot of magic. This tiny box actually has a lot of magic in it. Because when I call next, I want to get e. But I want to come back here and keep going, right? So I have my code that is using the iterator. And there is this code here, that is sort of in a frozen state. Did you guys see any movies where people are frozen up and then, in the future, they are unfrozen and they start moving again? movies. All right, cool. So this is like that, this takes up the whole function, freezes it up and puts it in a box here. And it returns an iterator that can use the box in the future. So when you call next, it gives e, which is the guy that you put in here. And then it take the function out of the box, unfreezes it, and lets it run again until it hits yield again. Then what happens the next time it hits yield? So, you are looping, and you are yielding again. And say this time you are yielding. Just do the same thing? Do you put it in that iterator? Or do you make another iterator? Same iterator. So while this is looping, the code outside should get the values that it is yielding. So this has to behave as one iterator. So the code is unfrozen, it is allowed to execute until it says yield again. And then it says yield with a new element. I put this guy in the box. Then I return the old guy as the return value for next. Oh. And then it is frozen again. So this guy is still in a frozen state. In the movies, I think you are only unfrozen once. And then you keep going, right? And there is a happy ending. Where here, every time you call yield you are frozen again, until someone calls next. Does this make sense? It is kind of like Groundhog Day. Yes, except you are allowed to go forward. So this keeps going forward. up, thought. So it is looping. It is the same day, really. It is doing different things, though. Yeah. But all your state is saved. So there, some of the state is rolled back. Here all the state is saved. OK. OK, but if that analogy helps, keep it. When you call next, are you computing e or e prime to be returned? So when you are calling next, you are computing e prime and returning e. So the value you get from next is pre computed? So the value you get form next is what you yielded before. Wait, so you would just take some sequence hashes instance of that, and then just by putting in yield, now it is magically become an iterator and you can call that next on it? Yep. And inside, you do not have to know that it is an iterator. So you do not have a method next here, right? I do not implement next or iter here. I write this as if it is printing stuff to the output. You can think of yield is a print. If you wanted an iterator, then pretend you are printing what you want to iterate over. And instead of saying print you say yield. And then you use that. OK, now what happens when we are done? What happens when this loop is done and you return from this method? We said there is no return value. It raises a stop? So when we return, it is going to keep in have to remember that it is done, right? And the first time, it has some element here that it has to return. So every time you call yield we put a new element in the box, and return the old one. So now we would return the old one. We have returned e prime, take it out, and put done in the box. So in the future, if next is called again, raise stop iteration. No more freezing, unfreezing, because we are done. We are returned. So if you called next it would just give you nothing? It has to raise this exception. So you mean, like oh, so it oh, I see. It would give you red text then? If you called it directly, yes, it would give you red text. Yes? So this takes a sequence or a list, not another iterator, ever? This? What is this? This other code here? Yeah. Not necessarily. Or you could give it a procedure. I can give it an iterator if I am iterating over it using for in. Like, for something in one iterator, yield that something, and then Oh, OK. Yeah, that is a good point. I will get to that later, when we talk about how we are going to solve the PSET. No, we are not solving the PSET for you. But we will talk about it a little bit. But yeah, that is a good point. So there is no reason why you ca not have an argument here that, either a list or an iterator, and then you are iterating over it. And then you have nested generators. So you have generators returned in other generators, and you have a whole chain of things happening when you say next. Wait, so this is a generator then, because it produces well it is an iterator though? So a generator returns an iterator from this method. So a generator acts like an iterator, except when you call next, it unfreezes this code here, and it let is it run. But I mean, it is basically an iterator then? Yeah. But we are just calling it a generator because Because there is a lot more magic. OK. So an iterator just says next and iter. This is all that an iterator is, nothing more. Any object that has these two methods is an iterator. Oh, OK. Now a generator is a piece of Python magic that let is you write shorter iterators. So three lines, as opposed to thirteen lines. And we came up with a way to turn in a code that would build a list, and easily turn it into a code that uses a generator, and that uses constant memory instead of building that list. OK, now I know how an iterator functions. Exactly. OK, do generators make sense now? Yes. If you wanted to loop through all of the values in a generator, do you just wait until the exception is raised? Or should you, like, keep track of how many things are going to be in that generator? So, when you have a generator, you had have no idea how many things there are. That is a good point. So you are wondering if I have an iterator, say any iterator, not necessarily a generator, how do I know how many things it is going to return, right? Do I have ln? I do not have ln. So an iterator does not have ln. So you have to iterate through it. And most importantly, some iterators can never return. So you can have an iterator that streams data for you across the network. Or you can have an iterator that iterates over the Fibonacci numbers. That is an infinite sequence, right? It is never going to end. So ln would not even be defined then. Good question, I like it. Is there an is next method for either iterators or generators? Nope. This is what you get, if there is no in. If that is mature then Yeah. So in Java you have this belief that you should not get exceptions. You should be able to check for them, right? So maybe that is why you are asking. So if people coming from Java know that any time a method raises an exception, there should be another method that tells you whether this first method is going to raise an exception or not. In Python the exception is just raised. So exceptions are not a lot more expensive than regular instructions, because we are using an interpreted language, and it is already reasonably slow. So it can do exceptions for free, yay. So this is how it works. This is how for in works. Every time you do a for in, an exception is raised. We do not have to catch that, then? Nope, the for in catches it for you. That is tricky stuff. But it is nice because then you can build any iterator that acts like a list. And then you can do even more fancy stuff, and build a generator. And you are using constant memory instead of order and memory for producing an order and size list. Yes? So if we get passed in an iterator and then just yielded what we passed in, yielded the iterator, would that just, essentially, delay everything by one? So you are yielding the iterator as next, right? What? Yeah. You want to yield the iterator as next. Because if you yield the iterator object, you are going to return that object every time. So you are thinking of something that So you need to increase You will yield up next, right? Right. You can have a method that says this is the method. And then you take in an iterator. And then you yield it up next. But then you will, basically, get the same thing. The same thing. But is it delayed by one or no? Nope. No, so you have to work through this to convince yourself that it is not delayed. So if it would be delayed by one, what is the first thing that you are yielding. I do not know. Yeah, so no delay. OK. OK, cool. So let is see, what do we have to implement in DNA seq, sub sequence hashes. Do people have an idea of how to implement that now? Yes? Does it make sense for everyone? So you build it as if you were building a list, and then you use yield to make it fast. And by fast I mean less memory. OK, how about interval sub sequence hashes? The one below. Is that just like rolling hash, except you, like, have a step in your range? OK, so it is like having a step in your range. So how can you do that? What is one way of doing it? hashes? Did anyone solve the PSET yet? Yes, OK how did you guys do it? Wait, no. That is a bad question because you guys can answer too much. So interval sub sequence hashes versus sub sequence hashes. Did you copy paste the code? Absolutely. OK, so one way of doing it is copy and pasting the code. The problem if you copy paste the code is then you are not DRY. There is this engineering thing DRY means do not repeat yourself. So if you are not DRY, if you copy paste, then suppose you find the bug later. Suppose you run the big test and it crashes somewhere. And you fix a bug in sub sequence hashes. Oh, we are supposed to, like, call sub sequence hashes from interval sub sequence hashes, right? That is another way of doing it that is DRY. So this way you are not copy pasting the code. We are inlining the code. You are inlining it manually, right? All right. So the problem, if you do this on a large scale, like when you go work somewhere, is that you end up with twenty copies of the same code. And then five of them have bug fixes and the other fifteen do not, because people forgot where they are. So ideally, try to keep your code DRY. So, basically, a list of tuples, right? OK, so a list of tuples. What does a tuple have? The index at which the sub sequence operates? So two indexes, right? The index in the first sub sequence, say  OK, say i1 and then the index in a second sequence, for the same sub sequence, r right? And then i1, i2 prime, i1, i2 second, so on and so forth. So you have the same sub sequence in the first sequence matches more things in the second one. This is how you are supposed to return them. Does the order matter? I hope not. OK, any questions on this? We went through generators fast. You guys are smart. Yes? Can you explain how the imaging works? Like, how they create the on tuples. No.  Sorry, I do not know. Wait, which part? So we yield the tuples. But I do not really get how they come up with the image from it. From the tuples? Oh, I mean, I guess they are probably values. Yeah, because I thought if you compared two strings of DNA that had the exact same, I thought it would be like a diagonal line down, not just a small black box. OK. So I do not think I am understanding how they, like, image it. So you are supposed to get your image has some things here, and a match is going to give you a big diagonal line that is stronger than everything else, right? It is really fanned out. Well I do not have thin chalk. No, no, there is like one really dark black box, that is like really black. So I thought that meant that all the tuples are there, and everything else is just kind of gray. Good question. I will have to think about that supposed to be there. Is it like a notation thing, or I think that black box is supposed to be there. Did anyone try comparing two things that should not match, like the dog and the monkey? Yeah. And the entire thing was like dark. Yeah. against, like, two same DNAs everything was very light. And there was like a very, very light gray line. But I thought that would be like black. So I think how black it is means relative to all the sub sequences, how long it is how long the sub sequence you are recording is. Either that or how many. There is a function somewhere in there that computes the intensity of a pixel, that is square root of order four of something. OK, and I can look at that now and tell you. It is OK. It is not super important. Or we can talk about amortized analysis for a bit. Yay Let is talk about amortized analysis. So this is what you are supposed to get, that is what matters.  OK, so amortized analysis, what is the example that we talked about in class? It is like list expansion? OK, so you have you have a list. And we know that the list is stored as an array, right? So this means that you can do indexing in constant time. So if you want to get the first element, order one point If you want to get the millionth element, order one point This is not true if you had a link list instead. The millionth element would be order a million. So this is an array. What do we implement? What is the operation that we implement on this list? Insert Insert, append, push. Let is go for append, because that is what Python calls it. OK, so append puts an element at the end of the list, right? So how does append work? The array is not full. OK. So say I have some count variable here. So if the length of the array is bigger than count then what do I do? Then we can directly insert. And because we are looking up in an array and we are doing constant time. OK. And so an order amount of information in x? Sorry? Order amount of information of x? Or do we just Let is say this is our reference, so it is constant time. Otherwise we do not have enough room in our array. So we need to make it bigger. OK. So we have array two becomes new array of size two times count, right? Copy everything from length of the array. I guess they are the same. I hope they are the same. It is. Yeah, I had say that. So copy from array to let is do this to array two point And then array two becomes array. And then this code here goes here, right? So there is a better way to write this if statement so the code is not duplicated. OK, so if the length is bigger than how many elements I have, if I still have room in the array, what is the cost? What is the running time? Constant. Oh, let is put it on the left. OK, if I have to resize the array, what is the cost?  So, if I did an operations, what then, right? N is the size of the array. If the only operation I have is append, then I can say n operations will cause the array of grow to size n. So n where n is the number of operations. You mean, like, re adding to the So an operation is a data structure operation, like a query or an update. This is my update and this is my query. Wait, but like, it is order n though, because Yeah. I know, it is order n. But because we have like an array, and then you have to make a new one, and you have to move all those old items over, right? Yep. OK. But, I mean, sometimes like, if your actual array, if you expand it before like, let is say you notice you are getting full and you decide to like make it bigger at that point, is it still order n, as in the number of elements that are It depends on how you decide. There is a problem on the PSET that asks you about that. So, depends on when you make the decision and how you make the decision, the answer is either yes, you are still constant time, or no. So if you understand the amortized analysis then you can argue of whether it still holds or not. If this breaks down at any point, not going to be constant time. Yes? So the only cost is really copying everything from the old array to the new array? Yes. Actually allocating that space is We assume that allocating the space is constant time. Good question, because you ca not take that for granted, right? So we assume that this is order 1, copying is order n. And then the insertion is order 1, just like before. So allocating may not be constant. In real life, allocating is actually logarithmic either of the size that you are asking for or logarithmic of how many buffers you have allocated. And you can make a constant time allocator. But that is lower than a logarithmic allocator, because the constant factor behind it is so big. But even if this allocation would be order n, which would be terrible, it would still get absorbed here. So the overall model works no matter what the allocation is. It is reasonable, from a theoretical standpoint, to say that allocation is order 1, from a theoretical standpoint. So this is the real cost copying the elements. And this makes an append order n worst case. So if you look at this data structure then suppose we want to compute the cost of an append. So say we have code like this, 4, 1, 2, n. First we have L be an empty list. Then we want to compute the cost of this. So if we do it without amortized analysis, line by line analysis, just like we learned in the first lecture, what is the cost of this, making a new list constant? What is the cost of one append? Constant. One append. So an append can either branch here or branch here. So what is the cost of one append? It would be showing with an empty list? Depends. It depends. So worst case. We have to look at a worst case. So this is line by line analysis. We are going to get one number for this. N. An n. Yep. So in the worst case, the list will be full. And you will have to make a new one. And then you are going on this branch of the if, so the cost is order n. So order n, worst case. So the cost of one call is order n, worst case. How many calls do we make? So what is the total cost of this thing? It is not actually n squared. Yes, it is not actually n squared. But if we do line by line analysis, before we learn amortized analysis, all we can say it is order of n squared. And this is correct, it is not bigger than n squared, right? So O is correct. But it is not the tight bound. So if we had a multiple choice, and you selected this, you would not get the score because we usually ask you what the tightest bound that you can get. OK, so line by line analysis. We worked through that a lot in doc dist. Does not work all the time. When it does not work, we tell you to use amortized analysis instead. So what is the goal of amortized analysis? What do we want? You guys are yelling at me that this is not n squared, why? I mean not why, what? What is it instead? What do we want from amortized analysis?  It is a that is an n. So we want amortized analysis to say that this is order one amortized, and this is ALARM SOUNDING Am I out of time? Yeah. OK, so there is a difference between the worst case and amortized, right? We can argue that this is order one amortized. And if this is order one amortized, then this is order n amortized. So does the difference between worst case and amortized make sense now? So this is what I want, the rest is fancy math. If you forget the fancy math after you are done with this class, that is OK. If you remember that this is order one amortized, and that is order n amortized, that is good. That is all you need to know to write code if you do not design algorithms. So this is an important piece of knowledge on its own. OK, so questions about the difference between worst case and amortized? OK, what does amortized mean? Average. Yep, averaged out over multiple operations. So instead of doing line by line analysis, we have to look at what happens over multiple operations, right? So there are two methods that I think are useful in CLRS. There are three in total, but the last one is horribly complicated. So there is something called aggregate analysis. And there is something called the cost based accounting. So last time when we looked at the costs for append, we argued that, hey, it is order one for a lot of times. And then it is only order n for an operation that is a power of two point So if we are looking at the K ith append, then this is order K for K equals two to the i. And it is order one otherwise. Right? So if we sum up all these costs, we get plus sum over log n of O of two to the i. And this is clearly order n. And if you do the math here, this is also order n. So this is aggregate analysis. This is what we taught you in lecture. Does this make sense? So the key here is that whenever we are increasing the array, we are increasing it to two times. And we start with a size of 1, count is one point We start with an array with one element. So the size of the array will first be 1, then 2, then 4, then 8, then 16, 32, 64, 128, so on so forth. It increases exponentially. So on the first append I will have to do a resize. On the second one, resize. Fourth one, resize. Eighth, resize, so on and so forth. So if I am adding up the cost for n operations, each operation is order one because I am inserting everywhere. And then all these operations are all order n. But there is few of them. They are few and far out. So if you write the sum this way, and you do the math, you get that it is order n. So aggregate analysis says, look at n operations and add the costs up together. And last time we had that good example of walking over a tree, and in order traversal where we drew arrows across edges. So that is aggregate analysis. And then you should look at the cost method in CLRS because that is also useful sometimes. Does this help? Any questions? No, everyone wants to go home. Wait Almost. For log n, so you are starting from log n going to So I am starting from one going to log n. Oh, oh, so after you are buffering. So this is fancy math for saying only add up powers of two. So that is what I am trying to say, add these guys up. Well that is your step. Yeah. Oh, OK. Oh, I like that. OK. OK. 
</body>
</html>